{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"executionInfo":{"elapsed":55162,"status":"error","timestamp":1718285857806,"user":{"displayName":"Rajarshi Dey","userId":"16792560365877080833"},"user_tz":-330},"id":"NDLrumxPw1zK","outputId":"7aff5761-ad6b-495e-f994-443f132cf26f"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"]},{"ename":"InvalidArgumentError","evalue":"{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [10000,0] vs. [0,1] [Op:Sub] name: ","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-c0b4d13cac03>\u001b[0m in \u001b[0;36m<cell line: 74>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_flat_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_flat_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-c0b4d13cac03>\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(model, x, t, alpha, beta, v, D)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mu_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mu_xx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mriesz_space_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mpde_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu_t\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mu_x\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mu_xx\u001b[0m  \u001b[0;31m# Align shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpde_loss\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5982\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5983\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [10000,0] vs. [0,1] [Op:Sub] name: "]}],"source":["import tensorflow as tf\n","import numpy as np\n","import plotly.graph_objects as go\n","\n","# Define the neural network model\n","class PINN(tf.keras.Model):\n","    def __init__(self, activation='tanh'):\n","        super(PINN, self).__init__()\n","        self.hidden = [\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(1)\n","        ]\n","\n","    def call(self, inputs):\n","        for layer in self.hidden:\n","            inputs = layer(inputs)\n","        return inputs\n","\n","# Numerical approximation of the Caputo fractional derivative\n","def caputo_time_derivative(u, t, alpha):\n","    dt = t[1] - t[0]\n","    n = t.shape[0]\n","    term = 0\n","    for j in range(1, n):\n","        term += (u[:, j:j+1] - u[:, j-1:j]) / (dt**alpha) * (t[j:j+1] - t[j-1:j])**(1 - alpha)\n","    term = term[:, :-1]  # Correct shape to match\n","    return term / tf.exp(tf.math.lgamma(2 - alpha))\n","\n","# Numerical approximation of the Riesz fractional derivative\n","def riesz_space_derivative(u, x, beta):\n","    dx = x[1] - x[0]\n","    n = x.shape[0]\n","    term = 0\n","    for j in range(1, n-1):\n","        term += (u[j+1:j+2, :] - 2 * u[j:j+1, :] + u[j-1:j, :]) / (dx**beta) * (x[j+1:j+2] - x[j-1:j])**(2 - beta)\n","    term = term[:-2, :]  # Correct shape to match\n","    return term / tf.exp(tf.math.lgamma(3 - beta))\n","\n","# Loss function\n","def loss_function(model, x, t, alpha, beta, v, D):\n","    with tf.GradientTape(persistent=True) as tape:\n","        tape.watch([x, t])\n","        inputs = tf.concat([x, t], axis=1)\n","        u = model(inputs)\n","        u_t = caputo_time_derivative(u, t, alpha)\n","        u_x = tape.gradient(u, x)\n","        u_xx = riesz_space_derivative(u, x, beta)\n","    pde_loss = u_t + v * u_x - D * u_xx  # Align shapes\n","    return tf.reduce_mean(pde_loss**2)\n","\n","# Training\n","model = PINN()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","\n","# Define training data (example)\n","x = np.linspace(0, 1, 100).reshape(-1, 1).astype(np.float32)\n","t = np.linspace(0, 1, 100).reshape(-1, 1).astype(np.float32)\n","X, T = np.meshgrid(x, t)\n","X_flat = X.flatten().reshape(-1, 1)\n","T_flat = T.flatten().reshape(-1, 1)\n","\n","X_flat_tensor = tf.convert_to_tensor(X_flat, dtype=tf.float32)\n","T_flat_tensor = tf.convert_to_tensor(T_flat, dtype=tf.float32)\n","\n","alpha = 0.8  # example value\n","beta = 1.5  # example value\n","v = 1.0  # example value\n","D = 1.0  # example value\n","\n","# Training loop\n","epochs = 1000\n","for epoch in range(epochs):\n","    with tf.GradientTape() as tape:\n","        loss = loss_function(model, X_flat_tensor, T_flat_tensor, alpha, beta, v, D)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    if epoch % 100 == 0:\n","        print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n","\n","# Plotting the result using Plotly\n","u_pred = model(tf.concat([X_flat_tensor, T_flat_tensor], axis=1)).numpy().reshape(100, 100)\n","\n","fig = go.Figure(data=[\n","    go.Surface(z=u_pred, x=X, y=T, colorscale='Viridis')\n","])\n","\n","fig.update_layout(\n","    title='Predicted Solution u(x,t)',\n","    scene=dict(\n","        xaxis_title='x',\n","        yaxis_title='t',\n","        zaxis_title='u(x,t)',\n","        bgcolor='white'\n","    ),\n","    autosize=False,\n","    width=700,\n","    height=700,\n","    margin=dict(l=65, r=50, b=65, t=90)\n",")\n","\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9573,"status":"ok","timestamp":1718425903091,"user":{"displayName":"Rajarshi Dey","userId":"16792560365877080833"},"user_tz":-330},"id":"nfT21O9WbfAe","outputId":"38101c80-3e40-4616-b11c-7403ac5bee70"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting numfracpy\n","  Downloading numfracpy-0.4-py3-none-any.whl (7.0 kB)\n","Installing collected packages: numfracpy\n","Successfully installed numfracpy-0.4\n"]}],"source":["pip install numfracpy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2040,"status":"ok","timestamp":1718425913632,"user":{"displayName":"Rajarshi Dey","userId":"16792560365877080833"},"user_tz":-330},"id":"qst8kKj30830","outputId":"f46abb44-e951-4206-85b4-bc04dfa349fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Caputo_der1', 'Caputo_der2', 'FODE', 'GLDer1', 'GLDer2', 'LTInversion', 'MittagLeffler_one_fsum', 'MittagLeffler_two_fsum', 'Mittag_Leffler_one', 'Mittag_Leffler_three', 'Mittag_Leffler_two', 'OptimalParam_RB', 'OptimalParam_RU', 'RL_der1', 'RL_der2', 'RL_integral', 'SystemFODEs', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'epsilon', 'integrate', 'log_epsilon', 'math', 'np', 'special']\n"]}],"source":["import numfracpy as nfp\n","\n","print(dir(nfp))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J5OoiyDx0myk"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import plotly.graph_objects as go\n","from scipy.special import gamma\n","\n","# Define the neural network model\n","class PINN(tf.keras.Model):\n","    def __init__(self, activation='tanh'):\n","        super(PINN, self).__init__()\n","        self.hidden = [\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(1)\n","        ]\n","\n","    def call(self, inputs):\n","        for layer in self.hidden:\n","            inputs = layer(inputs)\n","        return inputs\n","\n","# Numerical approximation of the Caputo fractional derivative\n","def caputo_time_derivative(u, t, alpha):\n","    dt = t[1, 0] - t[0, 0]\n","    u_np = u.numpy()\n","    u_t = np.zeros_like(u_np)\n","    for i in range(1, u_np.shape[0]):\n","        sum_term = 0\n","        for k in range(i):\n","            sum_term += (u_np[k] - u_np[k - 1]) / ((t[i] - t[k])**(1 + alpha))\n","        u_t[i] = dt**alpha / gamma(2 - alpha) * sum_term\n","    return tf.convert_to_tensor(u_t, dtype=tf.float32)\n","\n","# Numerical approximation of the Riesz fractional derivative\n","def riesz_space_derivative(u, x, beta):\n","    dx = x[1, 0] - x[0, 0]\n","    u_np = u.numpy()\n","    u_xx = np.zeros_like(u_np)\n","    for i in range(1, u_np.shape[0] - 1):\n","        sum_term = 0\n","        for k in range(1, u_np.shape[1] - 1):\n","            sum_term += (u_np[i, k + 1] - 2 * u_np[i, k] + u_np[i, k - 1]) / ((x[i] - x[k])**(1 + beta))\n","        u_xx[i] = dx**beta / gamma(2 - beta) * sum_term\n","    return tf.convert_to_tensor(u_xx, dtype=tf.float32)\n","\n","# Loss function\n","def loss_function(model, x, t, alpha, beta, v, D):\n","    with tf.GradientTape(persistent=True) as tape:\n","        tape.watch([x, t])\n","        inputs = tf.concat([x, t], axis=1)\n","        u = model(inputs)\n","        u_t = caputo_time_derivative(u, t, alpha)\n","        u_x = tape.gradient(u, x)\n","        u_xx = riesz_space_derivative(u, x, beta)\n","    pde_loss = u_t + v * u_x - D * u_xx\n","    return tf.reduce_mean(pde_loss**2)\n","\n","# Training\n","model = PINN()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","\n","# Define training data (example)\n","x = np.linspace(0, 1, 100).reshape(-1, 1).astype(np.float32)\n","t = np.linspace(0, 1, 100).reshape(-1, 1).astype(np.float32)\n","X, T = np.meshgrid(x, t)\n","X_flat = X.flatten().reshape(-1, 1)\n","T_flat = T.flatten().reshape(-1, 1)\n","\n","X_flat_tensor = tf.convert_to_tensor(X_flat, dtype=tf.float32)\n","T_flat_tensor = tf.convert_to_tensor(T_flat, dtype=tf.float32)\n","\n","alpha = 0.8  # example value\n","beta = 1.5  # example value\n","v = 1.0  # example value\n","D = 1.0  # example value\n","\n","# Training loop\n","epochs = 1000\n","for epoch in range(epochs):\n","    with tf.GradientTape() as tape:\n","        loss = loss_function(model, X_flat_tensor, T_flat_tensor, alpha, beta, v, D)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    if epoch % 100 == 0:\n","        print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n","\n","# Plotting the result using Plotly\n","u_pred = model(tf.concat([X_flat_tensor, T_flat_tensor], axis=1)).numpy().reshape(100, 100)\n","\n","fig = go.Figure(data=[\n","    go.Surface(z=u_pred, x=X, y=T, colorscale='Viridis')\n","])\n","\n","fig.update_layout(\n","    title='Predicted Solution u(x,t)',\n","    scene=dict(\n","        xaxis_title='x',\n","        yaxis_title='t',\n","        zaxis_title='u(x,t)',\n","        bgcolor='white'\n","    ),\n","    autosize=False,\n","    width=700,\n","    height=700,\n","    margin=dict(l=65, r=50, b=65, t=90)\n",")\n","\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yWItsWyv0ySS","outputId":"0be292c5-673e-435f-b04a-78ec8ab0b533"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0, Loss: nan\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import plotly.graph_objects as go\n","from scipy.special import gamma\n","\n","# Define the neural network model\n","class PINN(tf.keras.Model):\n","    def __init__(self, activation='tanh'):\n","        super(PINN, self).__init__()\n","        self.hidden = [\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(1)\n","        ]\n","\n","    def call(self, inputs):\n","        for layer in self.hidden:\n","            inputs = layer(inputs)\n","        return inputs\n","\n","def caputo_time_derivative(u, t, alpha):\n","    dt = t[1, 0] - t[0, 0]\n","    u_flat = tf.reshape(u, [-1])\n","    t_flat = tf.reshape(t, [-1])\n","    u_t = tf.zeros_like(u_flat)\n","\n","    for i in range(1, len(u_flat)):\n","        t_diff = (t_flat[i] - t_flat[:i])**(1 + alpha)\n","        u_diff = (u_flat[1:i+1] - u_flat[:i])\n","        u_t = u_t + tf.concat([tf.zeros(i), tf.reduce_sum(u_diff / t_diff) * tf.ones(1), tf.zeros(len(u_flat) - i - 1)], axis=0)\n","\n","    u_t = dt**alpha / gamma(2 - alpha) * u_t\n","    return tf.reshape(u_t, [-1, 1])\n","\n","\n","def riesz_space_derivative(u, x, beta):\n","    dx = x[1, 0] - x[0, 0]\n","    u_flat = tf.reshape(u, [-1])\n","    x_flat = tf.reshape(x, [-1])\n","    u_xx = tf.zeros_like(u_flat)\n","\n","    for i in range(1, len(u_flat) - 1):\n","        x_diff = (x_flat[i] - x_flat[:i])**(1 + beta)\n","        u_diff = (u_flat[i+1:i+2] - 2 * u_flat[i:i+1] + u_flat[i-1:i])\n","        u_xx = u_xx + tf.concat([tf.zeros(i), tf.reduce_sum(u_diff / x_diff) * tf.ones(1), tf.zeros(len(u_flat) - i - 1)], axis=0)\n","\n","    u_xx = dx**beta / gamma(2 - beta) * u_xx\n","    return tf.reshape(u_xx, [-1, 1])\n","\n","\n","# Loss function\n","def loss_function(model, x, t, alpha, beta, v, D):\n","    with tf.GradientTape(persistent=True) as tape:\n","        tape.watch([x, t])\n","        inputs = tf.concat([x, t], axis=1)\n","        u = model(inputs)\n","        u_t = caputo_time_derivative(u, t, alpha)\n","        u_x = tape.gradient(u, x)\n","        u_xx = riesz_space_derivative(u, x, beta)\n","    pde_loss = u_t + v * u_x - D * u_xx\n","    return tf.reduce_mean(pde_loss**2)\n","\n","# Training\n","model = PINN()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","\n","# Define training data (example)\n","x = np.linspace(0, 1, 100).reshape(-1, 1).astype(np.float32)\n","t = np.linspace(0, 1, 100).reshape(-1, 1).astype(np.float32)\n","X, T = np.meshgrid(x, t)\n","X_flat = X.flatten().reshape(-1, 1)\n","T_flat = T.flatten().reshape(-1, 1)\n","\n","X_flat_tensor = tf.convert_to_tensor(X_flat, dtype=tf.float32)\n","T_flat_tensor = tf.convert_to_tensor(T_flat, dtype=tf.float32)\n","\n","alpha = 0.8  # example value\n","beta = 1.5  # example value\n","v = 1.0  # example value\n","D = 1.0  # example value\n","\n","# Training loop\n","epochs = 1000\n","for epoch in range(epochs):\n","    with tf.GradientTape() as tape:\n","        loss = loss_function(model, X_flat_tensor, T_flat_tensor, alpha, beta, v, D)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    if epoch % 100 == 0:\n","        print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n","\n","# Plotting the result using Plotly\n","u_pred = model(tf.concat([X_flat_tensor, T_flat_tensor], axis=1)).numpy().reshape(100, 100)\n","\n","fig = go.Figure(data=[\n","    go.Surface(z=u_pred, x=X, y=T, colorscale='Viridis')\n","])\n","\n","fig.update_layout(\n","    title='Predicted Solution u(x,t)',\n","    scene=dict(\n","        xaxis_title='x',\n","        yaxis_title='t',\n","        zaxis_title='u(x,t)',\n","        bgcolor='white'\n","    ),\n","    autosize=False,\n","    width=700,\n","    height=700,\n","    margin=dict(l=65, r=50, b=65, t=90)\n",")\n","\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":928},"id":"mJQ5AVy6mp_Q","executionInfo":{"status":"ok","timestamp":1718441646691,"user_tz":-330,"elapsed":1346149,"user":{"displayName":"Rajarshi Dey","userId":"16792560365877080833"}},"outputId":"b092feee-6988-461d-dac4-6ee2613d420c"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: nan\n","Epoch 100, Loss: nan\n","Epoch 200, Loss: nan\n","Epoch 300, Loss: nan\n","Epoch 400, Loss: nan\n","Epoch 500, Loss: nan\n","Epoch 600, Loss: nan\n","Epoch 700, Loss: nan\n","Epoch 800, Loss: nan\n","Epoch 900, Loss: nan\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"4ba8889e-91a9-46c9-9d51-b09282dc708b\" class=\"plotly-graph-div\" style=\"height:700px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4ba8889e-91a9-46c9-9d51-b09282dc708b\")) {                    Plotly.newPlot(                        \"4ba8889e-91a9-46c9-9d51-b09282dc708b\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0]],\"y\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1111111119389534,0.1111111119389534,0.1111111119389534,0.1111111119389534,0.1111111119389534,0.1111111119389534,0.1111111119389534,0.1111111119389534,0.1111111119389534,0.1111111119389534],[0.2222222238779068,0.2222222238779068,0.2222222238779068,0.2222222238779068,0.2222222238779068,0.2222222238779068,0.2222222238779068,0.2222222238779068,0.2222222238779068,0.2222222238779068],[0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408],[0.4444444477558136,0.4444444477558136,0.4444444477558136,0.4444444477558136,0.4444444477558136,0.4444444477558136,0.4444444477558136,0.4444444477558136,0.4444444477558136,0.4444444477558136],[0.5555555820465088,0.5555555820465088,0.5555555820465088,0.5555555820465088,0.5555555820465088,0.5555555820465088,0.5555555820465088,0.5555555820465088,0.5555555820465088,0.5555555820465088],[0.6666666865348816,0.6666666865348816,0.6666666865348816,0.6666666865348816,0.6666666865348816,0.6666666865348816,0.6666666865348816,0.6666666865348816,0.6666666865348816,0.6666666865348816],[0.7777777910232544,0.7777777910232544,0.7777777910232544,0.7777777910232544,0.7777777910232544,0.7777777910232544,0.7777777910232544,0.7777777910232544,0.7777777910232544,0.7777777910232544],[0.8888888955116272,0.8888888955116272,0.8888888955116272,0.8888888955116272,0.8888888955116272,0.8888888955116272,0.8888888955116272,0.8888888955116272,0.8888888955116272,0.8888888955116272],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]],\"z\":[[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null]],\"type\":\"surface\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"t\"}},\"zaxis\":{\"title\":{\"text\":\"u(x,t)\"}},\"bgcolor\":\"white\"},\"margin\":{\"l\":65,\"r\":50,\"b\":65,\"t\":90},\"title\":{\"text\":\"Predicted Solution u(x,t)\"},\"autosize\":false,\"width\":700,\"height\":700},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('4ba8889e-91a9-46c9-9d51-b09282dc708b');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}],"source":["import tensorflow as tf\n","import numpy as np\n","import plotly.graph_objects as go\n","from scipy.special import gamma\n","\n","# Define the neural network model\n","class PINN(tf.keras.Model):\n","    def __init__(self, activation='tanh'):\n","        super(PINN, self).__init__()\n","        self.hidden = [\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(1)\n","        ]\n","\n","    def call(self, inputs):\n","        for layer in self.hidden:\n","            inputs = layer(inputs)\n","        return inputs\n","\n","# Numerical approximation of the Caputo fractional derivative using TensorFlow operations\n","def caputo_time_derivative(u, t, alpha):\n","    dt = t[1, 0] - t[0, 0]\n","    u_flat = tf.reshape(u, [-1])\n","    t_flat = tf.reshape(t, [-1])\n","    u_t = tf.zeros_like(u_flat)\n","\n","    for i in range(1, len(u_flat)):\n","        t_diff = (t_flat[i] - t_flat[:i])**(1 + alpha)\n","        u_diff = (u_flat[1:i+1] - u_flat[:i])\n","        u_t = u_t + tf.concat([tf.zeros(i), tf.reduce_sum(u_diff / t_diff) * tf.ones(1), tf.zeros(len(u_flat) - i - 1)], axis=0)\n","\n","    u_t = dt**alpha / gamma(2 - alpha) * u_t\n","    return tf.reshape(u_t, [-1, 1])\n","\n","# Numerical approximation of the Riesz fractional derivative using TensorFlow operations\n","def riesz_space_derivative(u, x, beta):\n","    dx = x[1, 0] - x[0, 0]\n","    u_flat = tf.reshape(u, [-1])\n","    x_flat = tf.reshape(x, [-1])\n","    u_xx = tf.zeros_like(u_flat)\n","\n","    for i in range(1, len(u_flat) - 1):\n","        x_diff = (x_flat[i] - x_flat[:i])**(1 + beta)\n","        u_diff = (u_flat[i+1:i+2] - 2 * u_flat[i:i+1] + u_flat[i-1:i])\n","        u_xx = u_xx + tf.concat([tf.zeros(i), tf.reduce_sum(u_diff / x_diff) * tf.ones(1), tf.zeros(len(u_flat) - i - 1)], axis=0)\n","\n","    u_xx = dx**beta / gamma(2 - beta) * u_xx\n","    return tf.reshape(u_xx, [-1, 1])\n","\n","# Loss function\n","def loss_function(model, x, t, alpha, beta, v, D):\n","    with tf.GradientTape(persistent=True) as tape:\n","        tape.watch([x, t])\n","        inputs = tf.concat([x, t], axis=1)\n","        u = model(inputs)\n","        u_t = caputo_time_derivative(u, t, alpha)\n","        u_x = tape.gradient(u, x)\n","        u_xx = riesz_space_derivative(u, x, beta)\n","    pde_loss = u_t + v * u_x - D * u_xx\n","    return tf.reduce_mean(pde_loss**2)\n","\n","# Training\n","model = PINN()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","\n","# Define training data (example)\n","x = np.linspace(0, 1, 10).reshape(-1, 1).astype(np.float32)\n","t = np.linspace(0, 1, 10).reshape(-1, 1).astype(np.float32)\n","X, T = np.meshgrid(x, t)\n","X_flat = X.flatten().reshape(-1, 1)\n","T_flat = T.flatten().reshape(-1, 1)\n","\n","X_flat_tensor = tf.convert_to_tensor(X_flat, dtype=tf.float32)\n","T_flat_tensor = tf.convert_to_tensor(T_flat, dtype=tf.float32)\n","\n","alpha = 0.8  # example value\n","beta = 1.5  # example value\n","v = 1.0  # example value\n","D = 1.0  # example value\n","\n","# Training loop\n","epochs = 1000\n","for epoch in range(epochs):\n","    with tf.GradientTape() as tape:\n","        loss = loss_function(model, X_flat_tensor, T_flat_tensor, alpha, beta, v, D)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    if epoch % 100 == 0:\n","        print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n","\n","# Plotting the result using Plotly\n","# Predicting u_pred\n","predictions = model(tf.concat([X_flat_tensor, T_flat_tensor], axis=1))\n","u_pred = predictions.numpy().reshape(X.shape)  # Reshape to match X (100x100 grid)\n","\n","# Plotting the result using Plotly\n","fig = go.Figure(data=[\n","    go.Surface(z=u_pred, x=X, y=T, colorscale='Viridis')\n","])\n","\n","fig.update_layout(\n","    title='Predicted Solution u(x,t)',\n","    scene=dict(\n","        xaxis_title='x',\n","        yaxis_title='t',\n","        zaxis_title='u(x,t)',\n","        bgcolor='white'\n","    ),\n","    autosize=False,\n","    width=700,\n","    height=700,\n","    margin=dict(l=65, r=50, b=65, t=90)\n",")\n","\n","fig.show()\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RkhZ0FVA4VRm","colab":{"base_uri":"https://localhost:8080/","height":772},"executionInfo":{"status":"ok","timestamp":1718507688519,"user_tz":-330,"elapsed":111345,"user":{"displayName":"Rajarshi Dey","userId":"16792560365877080833"}},"outputId":"5f874eee-efd4-4f9b-bef0-fc4bf913bab0"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: nan\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"71a82402-a57c-4cfc-be6a-02099629d2f7\" class=\"plotly-graph-div\" style=\"height:700px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"71a82402-a57c-4cfc-be6a-02099629d2f7\")) {                    Plotly.newPlot(                        \"71a82402-a57c-4cfc-be6a-02099629d2f7\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0]],\"y\":[[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.1111111640930176,1.1111111640930176,1.1111111640930176,1.1111111640930176,1.1111111640930176,1.1111111640930176,1.1111111640930176,1.1111111640930176,1.1111111640930176,1.1111111640930176],[1.2222222089767456,1.2222222089767456,1.2222222089767456,1.2222222089767456,1.2222222089767456,1.2222222089767456,1.2222222089767456,1.2222222089767456,1.2222222089767456,1.2222222089767456],[1.3333333730697632,1.3333333730697632,1.3333333730697632,1.3333333730697632,1.3333333730697632,1.3333333730697632,1.3333333730697632,1.3333333730697632,1.3333333730697632,1.3333333730697632],[1.4444444179534912,1.4444444179534912,1.4444444179534912,1.4444444179534912,1.4444444179534912,1.4444444179534912,1.4444444179534912,1.4444444179534912,1.4444444179534912,1.4444444179534912],[1.5555555820465088,1.5555555820465088,1.5555555820465088,1.5555555820465088,1.5555555820465088,1.5555555820465088,1.5555555820465088,1.5555555820465088,1.5555555820465088,1.5555555820465088],[1.6666666269302368,1.6666666269302368,1.6666666269302368,1.6666666269302368,1.6666666269302368,1.6666666269302368,1.6666666269302368,1.6666666269302368,1.6666666269302368,1.6666666269302368],[1.7777777910232544,1.7777777910232544,1.7777777910232544,1.7777777910232544,1.7777777910232544,1.7777777910232544,1.7777777910232544,1.7777777910232544,1.7777777910232544,1.7777777910232544],[1.8888888359069824,1.8888888359069824,1.8888888359069824,1.8888888359069824,1.8888888359069824,1.8888888359069824,1.8888888359069824,1.8888888359069824,1.8888888359069824,1.8888888359069824],[2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0]],\"z\":[[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null]],\"type\":\"surface\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"t\"}},\"zaxis\":{\"title\":{\"text\":\"u(x,t)\"}},\"bgcolor\":\"white\"},\"margin\":{\"l\":65,\"r\":50,\"b\":65,\"t\":90},\"title\":{\"text\":\"Predicted Solution u(x,t)\"},\"autosize\":false,\"width\":700,\"height\":700},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('71a82402-a57c-4cfc-be6a-02099629d2f7');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}],"source":["import tensorflow as tf\n","import numpy as np\n","import plotly.graph_objects as go\n","from scipy.special import gamma\n","\n","# Define the neural network model\n","class PINN(tf.keras.Model):\n","    def __init__(self, activation='tanh'):\n","        super(PINN, self).__init__()\n","        self.hidden = [\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(1)\n","        ]\n","\n","    def call(self, inputs):\n","        for layer in self.hidden:\n","            inputs = layer(inputs)\n","        return inputs\n","\n","# Numerical approximation of the Caputo fractional derivative using TensorFlow operations\n","def caputo_time_derivative(u, t, alpha):\n","    dt = t[1] - t[0]\n","    u_flat = tf.reshape(u, [-1])\n","    t_flat = tf.reshape(t, [-1])\n","    u_t = tf.zeros_like(u_flat)\n","\n","    for i in range(1, len(u_flat)):\n","        t_diff = (t_flat[i] - t_flat[:i])**(1 + alpha)\n","        u_diff = (u_flat[1:i+1] - u_flat[:i])\n","        u_t = u_t + tf.concat([tf.zeros(i), tf.reduce_sum(u_diff / t_diff) * tf.ones(1), tf.zeros(len(u_flat) - i - 1)], axis=0)\n","\n","    u_t = dt**alpha / gamma(2 - alpha) * u_t\n","    return tf.reshape(u_t, [-1, 1])\n","\n","# Numerical approximation of the Riesz fractional derivative using TensorFlow operations\n","def riesz_space_derivative(u, x, beta):\n","    dx = x[1] - x[0]\n","    u_flat = tf.reshape(u, [-1])\n","    x_flat = tf.reshape(x, [-1])\n","    u_xx = tf.zeros_like(u_flat)\n","\n","    for i in range(1, len(u_flat) - 1):\n","        x_diff = (x_flat[i] - x_flat[:i])**(1 + beta)\n","        u_diff = (u_flat[i+1:i+2] - 2 * u_flat[i:i+1] + u_flat[i-1:i])\n","        u_xx = u_xx + tf.concat([tf.zeros(i), tf.reduce_sum(u_diff / x_diff) * tf.ones(1), tf.zeros(len(u_flat) - i - 1)], axis=0)\n","\n","    u_xx = dx**beta / gamma(2 - beta) * u_xx\n","    return tf.reshape(u_xx, [-1, 1])\n","\n","# Loss function\n","def loss_function(model, x, t, alpha, beta, v, D):\n","    with tf.GradientTape(persistent=True) as tape:\n","        tape.watch(x)\n","        tape.watch(t)\n","        inputs = tf.concat([x, t], axis=1)\n","        u = model(inputs)\n","        u_x = tape.gradient(u, x)\n","    u_t = caputo_time_derivative(u, t, alpha)\n","    u_xx = riesz_space_derivative(u, x, beta)\n","    pde_loss = u_t + v * u_x - D * u_xx\n","    return tf.reduce_mean(pde_loss**2)\n","\n","# Training\n","model = PINN()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","\n","# Define training data\n","x = np.linspace(0, 1, 10).reshape(-1, 1).astype(np.float32)\n","t = np.linspace(1, 2, 10).reshape(-1, 1).astype(np.float32)\n","X, T = np.meshgrid(x, t)\n","X_flat = X.flatten().reshape(-1, 1)\n","T_flat = T.flatten().reshape(-1, 1)\n","\n","X_flat_tensor = tf.convert_to_tensor(X_flat, dtype=tf.float32)\n","T_flat_tensor = tf.convert_to_tensor(T_flat, dtype=tf.float32)\n","\n","# Generate initial condition u(x,0) = sin(pi * x)\n","initial_condition = np.sin(np.pi * x).astype(np.float32)\n","\n","# Training loop\n","alpha = 0.8  # example value\n","beta = 1.2  # example value\n","v = 1.0  # example value\n","D = 1.0  # example value\n","\n","epochs = 100\n","for epoch in range(epochs):\n","    with tf.GradientTape() as tape:\n","        loss = loss_function(model, X_flat_tensor, T_flat_tensor, alpha, beta, v, D)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    if epoch % 100 == 0:\n","        print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n","\n","# Predicting u_pred\n","predictions = model(tf.concat([X_flat_tensor, T_flat_tensor], axis=1))\n","u_pred = predictions.numpy().reshape(X.shape)  # Reshape to match X (50x50 grid)\n","\n","# Plotting the result using Plotly\n","fig = go.Figure(data=[\n","    go.Surface(z=u_pred, x=X, y=T, colorscale='Viridis')\n","])\n","\n","fig.update_layout(\n","    title='Predicted Solution u(x,t)',\n","    scene=dict(\n","        xaxis_title='x',\n","        yaxis_title='t',\n","        zaxis_title='u(x,t)',\n","        bgcolor='white'\n","    ),\n","    autosize=False,\n","    width=700,\n","    height=700,\n","    margin=dict(l=65, r=50, b=65, t=90)\n",")\n","\n","fig.show()\n"]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import plotly.graph_objects as go\n","\n","# Define the neural network model\n","class PINN(tf.keras.Model):\n","    def __init__(self, activation='tanh'):\n","        super(PINN, self).__init__()\n","        self.hidden = [\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(64, activation=activation),\n","            tf.keras.layers.Dense(1)\n","        ]\n","\n","    def call(self, inputs):\n","        for layer in self.hidden:\n","            inputs = layer(inputs)\n","        return inputs\n","\n","# Loss function\n","def loss_function(model, x, t, v, D):\n","    with tf.GradientTape(persistent=True) as tape:\n","        tape.watch(x)\n","        tape.watch(t)\n","        inputs = tf.concat([x, t], axis=1)\n","        u = model(inputs)\n","        u_x = tape.gradient(u, x)\n","        u_xx = tape.gradient(u_x, x)\n","        u_t = tape.gradient(u, t)\n","    pde_loss = u_t + v * u_x - D * u_xx\n","    return tf.reduce_mean(tf.square(pde_loss))\n","\n","# Training\n","model = PINN()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","\n","# Define training data\n","x = np.linspace(0, 1, 50).reshape(-1, 1).astype(np.float32)\n","t = np.linspace(0, 1, 50).reshape(-1, 1).astype(np.float32)\n","X, T = np.meshgrid(x, t)\n","X_flat = X.flatten().reshape(-1, 1)\n","T_flat = T.flatten().reshape(-1, 1)\n","\n","X_flat_tensor = tf.convert_to_tensor(X_flat, dtype=tf.float32)\n","T_flat_tensor = tf.convert_to_tensor(T_flat, dtype=tf.float32)\n","\n","# Generate initial condition u(x,0) = sin(pi * x)\n","initial_condition = np.sin(np.pi * x).astype(np.float32)\n","\n","# Training loop\n","v = 1.0  # example value\n","D = 1.0  # example value\n","\n","epochs = 1000\n","for epoch in range(epochs):\n","    with tf.GradientTape() as tape:\n","        loss = loss_function(model, X_flat_tensor, T_flat_tensor, v, D)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    if epoch % 100 == 0:\n","        print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n","\n","# Predicting u_pred\n","predictions = model(tf.concat([X_flat_tensor, T_flat_tensor], axis=1))\n","u_pred = predictions.numpy().reshape(X.shape)  # Reshape to match X (50x50 grid)\n","\n","# Plotting the result using Plotly\n","fig = go.Figure(data=[\n","    go.Surface(z=u_pred, x=X, y=T, colorscale='Viridis')\n","])\n","\n","fig.update_layout(\n","    title='Predicted Solution u(x,t)',\n","    scene=dict(\n","        xaxis_title='x',\n","        yaxis_title='t',\n","        zaxis_title='u(x,t)',\n","        bgcolor='white'\n","    ),\n","    autosize=False,\n","    width=700,\n","    height=700,\n","    margin=dict(l=65, r=50, b=65, t=90)\n",")\n","\n","fig.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"USqinJ9FxNQa","executionInfo":{"status":"ok","timestamp":1718507389766,"user_tz":-330,"elapsed":133325,"user":{"displayName":"Rajarshi Dey","userId":"16792560365877080833"}},"outputId":"d5fd1cc3-0dd6-4338-ac12-bb07126389db"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n","WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n","WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 0.001163708744570613\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 100, Loss: 5.352487278287299e-06\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 200, Loss: 2.2015210561221465e-06\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 300, Loss: 8.981759833659453e-07\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 400, Loss: 3.6880527432003873e-07\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 500, Loss: 1.9561746000817948e-07\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 600, Loss: 1.4493359401512862e-07\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 700, Loss: 1.2747661060075188e-07\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 800, Loss: 1.1763677321141586e-07\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 900, Loss: 1.0968921770881934e-07\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['pinn_1/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"b5abe46a-f669-4824-b780-8c1ebd16c12e\" class=\"plotly-graph-div\" style=\"height:700px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b5abe46a-f669-4824-b780-8c1ebd16c12e\")) {                    Plotly.newPlot(                        \"b5abe46a-f669-4824-b780-8c1ebd16c12e\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0],[0.0,0.020408162847161293,0.040816325694322586,0.06122449040412903,0.08163265138864517,0.10204081982374191,0.12244898080825806,0.1428571492433548,0.16326530277729034,0.18367347121238708,0.20408163964748383,0.22448979318141937,0.2448979616165161,0.26530611515045166,0.2857142984867096,0.30612245202064514,0.3265306055545807,0.3469387888908386,0.36734694242477417,0.3877550959587097,0.40816327929496765,0.4285714328289032,0.44897958636283875,0.4693877696990967,0.4897959232330322,0.5102040767669678,0.5306122303009033,0.5510203838348389,0.5714285969734192,0.5918367505073547,0.6122449040412903,0.6326530575752258,0.6530612111091614,0.6734693646430969,0.6938775777816772,0.7142857313156128,0.7346938848495483,0.7551020383834839,0.7755101919174194,0.795918345451355,0.8163265585899353,0.8367347121238708,0.8571428656578064,0.8775510191917419,0.8979591727256775,0.918367326259613,0.9387755393981934,0.9591836929321289,0.9795918464660645,1.0]],\"y\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293,0.020408162847161293],[0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586,0.040816325694322586],[0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903,0.06122449040412903],[0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517,0.08163265138864517],[0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191,0.10204081982374191],[0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806,0.12244898080825806],[0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548,0.1428571492433548],[0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034,0.16326530277729034],[0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708,0.18367347121238708],[0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383,0.20408163964748383],[0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937,0.22448979318141937],[0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161,0.2448979616165161],[0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166,0.26530611515045166],[0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096,0.2857142984867096],[0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514,0.30612245202064514],[0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807,0.3265306055545807],[0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386,0.3469387888908386],[0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417,0.36734694242477417],[0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097,0.3877550959587097],[0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765,0.40816327929496765],[0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032,0.4285714328289032],[0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875,0.44897958636283875],[0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967,0.4693877696990967],[0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322,0.4897959232330322],[0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678,0.5102040767669678],[0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033,0.5306122303009033],[0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389,0.5510203838348389],[0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192,0.5714285969734192],[0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547,0.5918367505073547],[0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903,0.6122449040412903],[0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258,0.6326530575752258],[0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614,0.6530612111091614],[0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969,0.6734693646430969],[0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772,0.6938775777816772],[0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128,0.7142857313156128],[0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483,0.7346938848495483],[0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839,0.7551020383834839],[0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194,0.7755101919174194],[0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355,0.795918345451355],[0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353,0.8163265585899353],[0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708,0.8367347121238708],[0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064,0.8571428656578064],[0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419,0.8775510191917419],[0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775,0.8979591727256775],[0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613,0.918367326259613],[0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934,0.9387755393981934],[0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289,0.9591836929321289],[0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645,0.9795918464660645],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]],\"z\":[[0.0014901496469974518,0.0010688602924346924,0.0006478205323219299,0.00022698566317558289,-0.00019365176558494568,-0.0006141066551208496,-0.001034427434206009,-0.0014546066522598267,-0.001874685287475586,-0.002294681966304779,-0.0027145855128765106,-0.003134429454803467,-0.003554265946149826,-0.0039740316569805145,-0.004393819719552994,-0.004813618957996368,-0.005233429372310638,-0.005653269588947296,-0.006073120981454849,-0.006492983549833298,-0.006912879645824432,-0.007332883775234222,-0.007752940058708191,-0.008172918111085892,-0.00859300047159195,-0.0090131014585495,-0.009433254599571228,-0.009853363037109375,-0.010273478925228119,-0.010693639516830444,-0.011113733053207397,-0.011533744633197784,-0.011953748762607574,-0.012373633682727814,-0.012793414294719696,-0.013213187456130981,-0.013632632791996002,-0.014052003622055054,-0.014471083879470825,-0.014890015125274658,-0.015308678150177002,-0.015727058053016663,-0.016144998371601105,-0.01656278222799301,-0.016979992389678955,-0.017396844923496246,-0.017813310027122498,-0.018229305744171143,-0.018644660711288452,-0.019059479236602783],[0.0018965136259794235,0.0014761444181203842,0.0010559745132923126,0.0006360001862049103,0.00021619908511638641,-0.00020347535610198975,-0.0006230250000953674,-0.0010424740612506866,-0.001461867243051529,-0.0018811598420143127,-0.0023004114627838135,-0.002719644457101822,-0.003138873726129532,-0.003558073192834854,-0.003977347165346146,-0.004396598786115646,-0.004815924912691116,-0.005235262215137482,-0.0056546591222286224,-0.006074175238609314,-0.006493646651506424,-0.006913222372531891,-0.007332846522331238,-0.007752552628517151,-0.008172206580638885,-0.008591968566179276,-0.00901174545288086,-0.009431548416614532,-0.009851381182670593,-0.010271191596984863,-0.010691054165363312,-0.011110670864582062,-0.011530399322509766,-0.011949971318244934,-0.01236945390701294,-0.012788787484169006,-0.013208001852035522,-0.01362699270248413,-0.014045827090740204,-0.014464259147644043,-0.014882579445838928,-0.015300512313842773,-0.01571814715862274,-0.01613543927669525,-0.016552120447158813,-0.01696860045194626,-0.017384514212608337,-0.017799988389015198,-0.018214955925941467,-0.018629178404808044],[0.0023019779473543167,0.0018825512379407883,0.0014632977545261383,0.0010442063212394714,0.0006252340972423553,0.00020639225840568542,-0.00021237879991531372,-0.0006310604512691498,-0.0010496899485588074,-0.0014682933688163757,-0.0018868930637836456,-0.0023054704070091248,-0.002724088728427887,-0.003142721951007843,-0.0035613514482975006,-0.003980092704296112,-0.004398901015520096,-0.004817713052034378,-0.00523662194609642,-0.005655597895383835,-0.0060746930539608,-0.006493803113698959,-0.0069130100309848785,-0.007332246750593185,-0.007751591503620148,-0.008170999586582184,-0.008590258657932281,-0.009009748697280884,-0.009429171681404114,-0.009848661720752716,-0.01026800274848938,-0.010687284171581268,-0.011106684803962708,-0.011525824666023254,-0.011945053935050964,-0.012363940477371216,-0.012782678008079529,-0.013201244175434113,-0.013619676232337952,-0.014037743210792542,-0.01445559412240982,-0.014873117208480835,-0.01529017835855484,-0.015706993639469147,-0.016123317182064056,-0.01653914898633957,-0.016954556107521057,-0.017369359731674194,-0.017783544957637787,-0.018197335302829742],[0.0027065053582191467,0.0022880304604768753,0.0018697213381528854,0.0014515258371829987,0.0010334514081478119,0.0006154142320156097,0.00019749626517295837,-0.00022042915225028992,-0.0006382875144481659,-0.0010561533272266388,-0.001474045217037201,-0.0018919631838798523,-0.0023098811507225037,-0.0027278847992420197,-0.0031459517776966095,-0.0035640746355056763,-0.003982279449701309,-0.004400588572025299,-0.004819005727767944,-0.005237460136413574,-0.005656037479639053,-0.006074666976928711,-0.006493397057056427,-0.006912171840667725,-0.007330998778343201,-0.007749997079372406,-0.008168905973434448,-0.008587867021560669,-0.009006910026073456,-0.009425938129425049,-0.009844906628131866,-0.010263852775096893,-0.010682754218578339,-0.01110144704580307,-0.011520110070705414,-0.011938586831092834,-0.01235692948102951,-0.012775011360645294,-0.013192929327487946,-0.013610519468784332,-0.014027848839759827,-0.014444753527641296,-0.014861367642879486,-0.01527753472328186,-0.01569320261478424,-0.016108475625514984,-0.01652321219444275,-0.016937434673309326,-0.017351068556308746,-0.01776401698589325],[0.003110017627477646,0.0026925448328256607,0.002275187522172928,0.0018579140305519104,0.0014407336711883545,0.0010236091911792755,0.0006064921617507935,0.00018942728638648987,-0.00022766366600990295,-0.0006447732448577881,-0.001061946153640747,-0.001479126513004303,-0.0018964000046253204,-0.0023137331008911133,-0.0027311742305755615,-0.0031486637890338898,-0.0035662688314914703,-0.003983963280916214,-0.004401780664920807,-0.004819713532924652,-0.005237758159637451,-0.005655840039253235,-0.00607406347990036,-0.006492346525192261,-0.006910689175128937,-0.007329151034355164,-0.007747642695903778,-0.008166089653968811,-0.008584700524806976,-0.009003221988677979,-0.009421736001968384,-0.009840212762355804,-0.010258466005325317,-0.010676734149456024,-0.011094793677330017,-0.01151273399591446,-0.011930681765079498,-0.012348152697086334,-0.012765496969223022,-0.013182565569877625,-0.013599254190921783,-0.014015637338161469,-0.014431573450565338,-0.014847218990325928,-0.015262126922607422,-0.015676699578762054,-0.016090795397758484,-0.01650427281856537,-0.016917020082473755,-0.017329208552837372],[0.0035124756395816803,0.003096010535955429,0.0026796385645866394,0.0022633299231529236,0.0018470436334609985,0.0014308243989944458,0.0010145865380764008,0.0005983412265777588,0.0001820884644985199,-0.00023422017693519592,-0.0006506145000457764,-0.0010670870542526245,-0.0014836005866527557,-0.0019002556800842285,-0.002316981554031372,-0.0027338676154613495,-0.003150835633277893,-0.003567919135093689,-0.003985099494457245,-0.004402466118335724,-0.0048198401927948,-0.005237460136413574,-0.00565512478351593,-0.00607280433177948,-0.006490640342235565,-0.006908513605594635,-0.007326453924179077,-0.007744483649730682,-0.008162438869476318,-0.008580461144447327,-0.008998371660709381,-0.009416274726390839,-0.009834080934524536,-0.01025177538394928,-0.010669328272342682,-0.011086702346801758,-0.011503942310810089,-0.011920928955078125,-0.012337654829025269,-0.012754008173942566,-0.013170003890991211,-0.013585671782493591,-0.014000967144966125,-0.014415755867958069,-0.01483020931482315,-0.015243880450725555,-0.01565711200237274,-0.01606975495815277,-0.016481630504131317,-0.01689300686120987],[0.003913793712854385,0.0034983642399311066,0.003083009272813797,0.002667665481567383,0.0022523850202560425,0.001837071031332016,0.001421712338924408,0.0010063424706459045,0.0005909167230129242,0.00017540156841278076,-0.00024015456438064575,-0.0006558187305927277,-0.0010716058313846588,-0.0014875642955303192,-0.001903574913740158,-0.002319730818271637,-0.002736032009124756,-0.0031524822115898132,-0.003568999469280243,-0.003985747694969177,-0.00440254807472229,-0.00481945276260376,-0.005236513912677765,-0.005653738975524902,-0.0060708969831466675,-0.0064882636070251465,-0.0069055259227752686,-0.007322914898395538,-0.007740356028079987,-0.008157752454280853,-0.008575081825256348,-0.008992373943328857,-0.009409569203853607,-0.009826652705669403,-0.010243572294712067,-0.010660335421562195,-0.01107681542634964,-0.011493220925331116,-0.011909179389476776,-0.012324832379817963,-0.012740135192871094,-0.013155072927474976,-0.013569653034210205,-0.013983689248561859,-0.014397084712982178,-0.014810077846050262,-0.01522248238325119,-0.01563413441181183,-0.01604529470205307,-0.016455620527267456],[0.004313956946134567,0.0038995742797851562,0.003485269844532013,0.003070913255214691,0.0026566050946712494,0.0022422410547733307,0.0018278434872627258,0.0014133453369140625,0.0009987801313400269,0.0005841776728630066,0.00016939640045166016,-0.0002454817295074463,-0.000660482794046402,-0.0010756216943264008,-0.0014908984303474426,-0.0019064098596572876,-0.002321965992450714,-0.002737671136856079,-0.0031535252928733826,-0.0035695433616638184,-0.003985688090324402,-0.004401996731758118,-0.004818379878997803,-0.005234882235527039,-0.005651511251926422,-0.0060681626200675964,-0.006484866142272949,-0.006901651620864868,-0.007318384945392609,-0.007735110819339752,-0.008151791989803314,-0.0085684135556221,-0.008984982967376709,-0.009401269257068634,-0.00981760025024414,-0.010233648121356964,-0.010649457573890686,-0.011065065860748291,-0.011480361223220825,-0.011895187199115753,-0.012309685349464417,-0.012723863124847412,-0.013137556612491608,-0.013550586998462677,-0.013963274657726288,-0.014375202357769012,-0.014786705374717712,-0.015197567641735077,-0.015607602894306183,-0.016016893088817596],[0.004712861031293869,0.004299584776163101,0.0038863010704517365,0.00347302109003067,0.003059700131416321,0.002646312117576599,0.0022328458726406097,0.001819312572479248,0.0014056563377380371,0.0009918808937072754,0.0005779825150966644,0.00016394630074501038,-0.00025025755167007446,-0.0006646141409873962,-0.0010790973901748657,-0.0014938116073608398,-0.001908630132675171,-0.002323620021343231,-0.0027387961745262146,-0.003154084086418152,-0.0035695508122444153,-0.0039851367473602295,-0.004400826990604401,-0.004816651344299316,-0.005232512950897217,-0.005648478865623474,-0.0060645416378974915,-0.006480604410171509,-0.006896644830703735,-0.007312662899494171,-0.007728651165962219,-0.008144617080688477,-0.008560344576835632,-0.00897601991891861,-0.00939149409532547,-0.009806811809539795,-0.010221868753433228,-0.010636582970619202,-0.011050961911678314,-0.011465020477771759,-0.011878766119480133,-0.01229184865951538,-0.012704737484455109,-0.013116933405399323,-0.013528510928153992,-0.01393958181142807,-0.0143500417470932,-0.014759838581085205,-0.015168771147727966,-0.015576913952827454],[0.005110457539558411,0.004698313772678375,0.004286132752895355,0.003873884677886963,0.003461625427007675,0.0030492357909679413,0.002636745572090149,0.002224147319793701,0.0018114298582077026,0.001398582011461258,0.0009855404496192932,0.0005723685026168823,0.00015904009342193604,-0.0002544671297073364,-0.0006681978702545166,-0.001082092523574829,-0.0014961063861846924,-0.0019103437662124634,-0.0023246929049491882,-0.0027392730116844177,-0.0031539946794509888,-0.0035688430070877075,-0.003983817994594574,-0.00439886748790741,-0.00481405109167099,-0.005229249596595764,-0.005644515156745911,-0.006059795618057251,-0.006475120782852173,-0.0068903639912605286,-0.007305651903152466,-0.00772075355052948,-0.008135765790939331,-0.008550673723220825,-0.008965276181697845,-0.009379729628562927,-0.009793885052204132,-0.010207772254943848,-0.010621413588523865,-0.011034436523914337,-0.011447206139564514,-0.011859424412250519,-0.012271210551261902,-0.012682467699050903,-0.013093136250972748,-0.0135030597448349,-0.013912491500377655,-0.014321096241474152,-0.014728844165802002,-0.01513586938381195],[0.0055067576467990875,0.005095701664686203,0.004684649407863617,0.004273504018783569,0.003862246870994568,0.0034509412944316864,0.003039449453353882,0.002627827227115631,0.0022160671651363373,0.0018041469156742096,0.0013920515775680542,0.0009797737002372742,0.000567309558391571,0.00015464425086975098,-0.00025819987058639526,-0.0006712228059768677,-0.0010844320058822632,-0.0014978498220443726,-0.0019114315509796143,-0.002325192093849182,-0.002739056944847107,-0.003153190016746521,-0.003567323088645935,-0.003981679677963257,-0.004395999014377594,-0.0048104822635650635,-0.00522497296333313,-0.005639523267745972,-0.006053902208805084,-0.006468497216701508,-0.00688287615776062,-0.007297083735466003,-0.0077113136649131775,-0.008125267922878265,-0.008539058268070221,-0.008952625095844269,-0.009365864098072052,-0.009778842329978943,-0.010191276669502258,-0.010603532195091248,-0.011015258729457855,-0.011426426470279694,-0.011837244033813477,-0.012247368693351746,-0.012656919658184052,-0.013065770268440247,-0.01347401738166809,-0.01388143002986908,-0.014287993311882019,-0.01469375193119049],[0.005901612341403961,0.005491737276315689,0.005081798881292343,0.004671778529882431,0.004261612892150879,0.003851335495710373,0.0034408830106258392,0.0030302926898002625,0.0026194974780082703,0.0022085905075073242,0.0017974376678466797,0.0013860687613487244,0.0009745508432388306,0.000562809407711029,0.0001508370041847229,-0.00026132166385650635,-0.0006736963987350464,-0.0010862499475479126,-0.0014990195631980896,-0.0019119232892990112,-0.0023249536752700806,-0.0027382075786590576,-0.0031515657901763916,-0.0035650134086608887,-0.0039785802364349365,-0.004392191767692566,-0.004805848002433777,-0.0052195265889167786,-0.005633138120174408,-0.00604681670665741,-0.006460264325141907,-0.006873704493045807,-0.007286980748176575,-0.007700011134147644,-0.008112788200378418,-0.008525408804416656,-0.008937753736972809,-0.009349778294563293,-0.009761199355125427,-0.010172262787818909,-0.010582990944385529,-0.010993175208568573,-0.011402696371078491,-0.011811807751655579,-0.012220025062561035,-0.012627728283405304,-0.013034641742706299,-0.013440825045108795,-0.013846166431903839,-0.014250688254833221],[0.006294999271631241,0.00588633120059967,0.00547756627202034,0.005068670958280563,0.004659626632928848,0.004250422120094299,0.003841061145067215,0.0034315064549446106,0.0030217543244361877,0.002611793577671051,0.0022016242146492004,0.0017912238836288452,0.0013806819915771484,0.0009698271751403809,0.0005587786436080933,0.0001475811004638672,-0.0002639293670654297,-0.0006755664944648743,-0.0010874196887016296,-0.0014995113015174866,-0.0019116699695587158,-0.0023239925503730774,-0.002736508846282959,-0.0031491219997406006,-0.003561750054359436,-0.003974519670009613,-0.004387229681015015,-0.004800058901309967,-0.005212761461734772,-0.005625471472740173,-0.0060380324721336365,-0.006450489163398743,-0.006862744688987732,-0.007274895906448364,-0.007686741650104523,-0.00809817761182785,-0.008509397506713867,-0.008920259773731232,-0.009330742061138153,-0.009740851819515228,-0.01015036553144455,-0.010559320449829102,-0.010967753827571869,-0.0113755464553833,-0.011782519519329071,-0.012189015746116638,-0.012594588100910187,-0.012999318540096283,-0.013403385877609253,-0.013806432485580444],[0.006686888635158539,0.006279401481151581,0.005871843546628952,0.005464106798171997,0.005056202411651611,0.004648145288228989,0.004239857196807861,0.0038313642144203186,0.0034226924180984497,0.0030137598514556885,0.0026046186685562134,0.002195216715335846,0.0017856284976005554,0.001375727355480194,0.0009656623005867004,0.0005553513765335083,0.00014487653970718384,-0.00026588886976242065,-0.0006768181920051575,-0.0010879337787628174,-0.0014992058277130127,-0.001910574734210968,-0.0023222044110298157,-0.0027338042855262756,-0.0031456276774406433,-0.00355733186006546,-0.003969199955463409,-0.004381075501441956,-0.004792742431163788,-0.005204439163208008,-0.005616024136543274,-0.006027489900588989,-0.006438799202442169,-0.006849825382232666,-0.007260575890541077,-0.007671132683753967,-0.008081197738647461,-0.008490905165672302,-0.0089002326130867,-0.009309090673923492,-0.009717412292957306,-0.010125227272510529,-0.010532282292842865,-0.010938748717308044,-0.011344559490680695,-0.011749669909477234,-0.012153774499893188,-0.012557148933410645,-0.012959733605384827,-0.01336127519607544],[0.0070771463215351105,0.006670955568552017,0.006264600902795792,0.005858078598976135,0.005451370030641556,0.005044393241405487,0.0046372562646865845,0.00422988086938858,0.0038222745060920715,0.0034144073724746704,0.003006279468536377,0.0025979727506637573,0.002189338207244873,0.0017805099487304688,0.001371428370475769,0.0009621083736419678,0.0005525797605514526,0.00014280527830123901,-0.00026717036962509155,-0.0006773471832275391,-0.0010876432061195374,-0.0014980435371398926,-0.0019086599349975586,-0.0023193657398223877,-0.002730138599872589,-0.0031409263610839844,-0.003551773726940155,-0.003962494432926178,-0.004373282194137573,-0.004783950746059418,-0.005194559693336487,-0.005604833364486694,-0.0060150474309921265,-0.006424963474273682,-0.006834685802459717,-0.00724395364522934,-0.007652930915355682,-0.008061528205871582,-0.008469551801681519,-0.0088772252202034,-0.009284190833568573,-0.00969068706035614,-0.010096475481987,-0.010501675307750702,-0.010905951261520386,-0.011309608817100525,-0.01171235740184784,-0.01211431622505188,-0.012515366077423096,-0.012915343046188354],[0.007465820759534836,0.007060889154672623,0.00665578618645668,0.006250455975532532,0.005844980478286743,0.005439206957817078,0.005033209919929504,0.0046269893646240234,0.0042204707860946655,0.003813736140727997,0.0034066811203956604,0.00299941748380661,0.0025918185710906982,0.002184048295021057,0.001775994896888733,0.001367725431919098,0.0009591728448867798,0.000550396740436554,0.0001414269208908081,-0.000267714262008667,-0.000676967203617096,-0.0010864362120628357,-0.0014959722757339478,-0.0019056573510169983,-0.0023153945803642273,-0.002725154161453247,-0.0031349360942840576,-0.0035446062684059143,-0.0039543211460113525,-0.004363924264907837,-0.004773341119289398,-0.005182608962059021,-0.005591675639152527,-0.006000421941280365,-0.0064089372754096985,-0.00681702047586441,-0.007224828004837036,-0.007632076740264893,-0.008038893342018127,-0.008445218205451965,-0.00885096937417984,-0.00925588607788086,-0.00966043770313263,-0.010063931345939636,-0.010466992855072021,-0.010869041085243225,-0.011270329356193542,-0.011670738458633423,-0.01207008957862854,-0.012468576431274414],[0.00785282626748085,0.007449202239513397,0.007045358419418335,0.006641283631324768,0.006237015128135681,0.005832448601722717,0.005427636206150055,0.0050225406885147095,0.004617221653461456,0.0042115747928619385,0.003805704414844513,0.0033994466066360474,0.0029930397868156433,0.002586282789707184,0.0021793097257614136,0.001772075891494751,0.0013646036386489868,0.0009569376707077026,0.000549018383026123,0.00014094263315200806,-0.0002673044800758362,-0.0006756633520126343,-0.0010841786861419678,-0.001492828130722046,-0.001901485025882721,-0.0023101866245269775,-0.0027188360691070557,-0.0031274333596229553,-0.0035359561443328857,-0.0039444416761398315,-0.004352658987045288,-0.004760816693305969,-0.005168654024600983,-0.0055761635303497314,-0.005983367562294006,-0.006390243768692017,-0.006796732544898987,-0.0072026327252388,-0.007608190178871155,-0.008012987673282623,-0.008417263627052307,-0.008821025490760803,-0.009223967790603638,-0.009626030921936035,-0.010027512907981873,-0.010428041219711304,-0.010827630758285522,-0.011226460337638855,-0.01162409782409668,-0.012020990252494812],[0.008238054811954498,0.007835760712623596,0.007433220744132996,0.0070304349064826965,0.006627395749092102,0.006224095821380615,0.005820520222187042,0.005416609346866608,0.005012430250644684,0.004607997834682465,0.00420321524143219,0.0037982091307640076,0.0033928528428077698,0.0029872357845306396,0.002581387758255005,0.00217524915933609,0.0017688572406768799,0.0013622641563415527,0.0009554624557495117,0.0005484521389007568,0.00014134496450424194,-0.0002659708261489868,-0.0006733536720275879,-0.0010808855295181274,-0.00148840993642807,-0.0018959194421768188,-0.0023034214973449707,-0.002710901200771332,-0.003118284046649933,-0.003525547683238983,-0.003932520747184753,-0.004339389503002167,-0.004746004939079285,-0.00515226274728775,-0.00555817037820816,-0.0059636905789375305,-0.00636880099773407,-0.006773322820663452,-0.007177397608757019,-0.007580816745758057,-0.007983729243278503,-0.008385792374610901,-0.008787214756011963,-0.009187906980514526,-0.00958755612373352,-0.009986668825149536,-0.01038464903831482,-0.01078169047832489,-0.011177599430084229,-0.011572450399398804],[0.008621521294116974,0.008220560848712921,0.007819369435310364,0.0074178725481033325,0.007016144692897797,0.006614074110984802,0.006211757659912109,0.005809120833873749,0.00540614128112793,0.005002886056900024,0.004599325358867645,0.004195444285869598,0.0037912577390670776,0.0033868104219436646,0.002982109785079956,0.002577163279056549,0.0021718889474868774,0.001766398549079895,0.0013607889413833618,0.0009549111127853394,0.0005488693714141846,0.00014270097017288208,-0.0002634674310684204,-0.0006697773933410645,-0.0010761916637420654,-0.0014825314283370972,-0.001888871192932129,-0.0022950172424316406,-0.0027011334896087646,-0.0031071528792381287,-0.0035129860043525696,-0.003918439149856567,-0.004323810338973999,-0.004728689789772034,-0.005133293569087982,-0.00553739070892334,-0.005941018462181091,-0.006344199180603027,-0.0067467838525772095,-0.007148638367652893,-0.007549911737442017,-0.007950633764266968,-0.008350417017936707,-0.008749306201934814,-0.009147465229034424,-0.009544700384140015,-0.009941041469573975,-0.010336220264434814,-0.01073049008846283,-0.011123508214950562],[0.00900309532880783,0.00860355794429779,0.008203715085983276,0.007803574204444885,0.007403172552585602,0.007002398371696472,0.00660136342048645,0.006199970841407776,0.005798228085041046,0.005396224558353424,0.004993908107280731,0.004591226577758789,0.004188269376754761,0.0037850216031074524,0.0033814609050750732,0.0029776543378829956,0.0025735944509506226,0.002169281244277954,0.0017648637294769287,0.001360177993774414,0.0009553581476211548,0.0005503818392753601,0.00014534592628479004,-0.00025975704193115234,-0.0006648525595664978,-0.0010699927806854248,-0.0014749914407730103,-0.0018799826502799988,-0.002284809947013855,-0.002689450979232788,-0.003093928098678589,-0.003498181700706482,-0.0039020180702209473,-0.004305601119995117,-0.004708737134933472,-0.005111321806907654,-0.005513608455657959,-0.005915224552154541,-0.0063161104917526245,-0.006716519594192505,-0.007116407155990601,-0.007515221834182739,-0.007913395762443542,-0.008310675621032715,-0.008707001805305481,-0.009102419018745422,-0.009496942162513733,-0.009890437126159668,-0.010282784700393677,-0.01067391037940979],[0.009382754564285278,0.008984655141830444,0.008586212992668152,0.008187510073184967,0.007788442075252533,0.007388949394226074,0.006989225745201111,0.006589129567146301,0.006188750267028809,0.005787983536720276,0.005386851727962494,0.004985451698303223,0.004583686590194702,0.004181660711765289,0.0037793591618537903,0.0033768266439437866,0.0029739290475845337,0.0025709494948387146,0.0021676570177078247,0.0017642080783843994,0.0013606101274490356,0.0009569749236106873,0.0005531236529350281,0.00014930963516235352,-0.0002545267343521118,-0.0006583034992218018,-0.0010620653629302979,-0.001465633511543274,-0.0018691718578338623,-0.002272479236125946,-0.0026756003499031067,-0.0030783414840698242,-0.0034808218479156494,-0.0038829445838928223,-0.0042845457792282104,-0.004685714840888977,-0.005086347460746765,-0.0054863691329956055,-0.005885720252990723,-0.006284594535827637,-0.0066825151443481445,-0.007079824805259705,-0.0074762701988220215,-0.007871747016906738,-0.008266299962997437,-0.008659988641738892,-0.009052470326423645,-0.009444132447242737,-0.009834498167037964,-0.010223671793937683],[0.009760484099388123,0.00936378538608551,0.008966818451881409,0.00856945663690567,0.008171766996383667,0.007773779332637787,0.0073753297328948975,0.006976604461669922,0.006577491760253906,0.006178013980388641,0.005778208374977112,0.005378104746341705,0.004977613687515259,0.004576921463012695,0.0041758716106414795,0.0037745460867881775,0.003372989594936371,0.0029712021350860596,0.0025691762566566467,0.002167023718357086,0.001764737069606781,0.001362331211566925,0.0009598955512046814,0.0005573108792304993,0.00015485286712646484,-0.00024765729904174805,-0.0006500110030174255,-0.0010522827506065369,-0.001454383134841919,-0.0018563270568847656,-0.002258017659187317,-0.002659246325492859,-0.003060072660446167,-0.0034606903791427612,-0.0038608163595199585,-0.0042604804039001465,-0.004659384489059448,-0.005057826638221741,-0.005455628037452698,-0.005852699279785156,-0.006248891353607178,-0.006644442677497864,-0.0070390403270721436,-0.007432669401168823,-0.00782535970211029,-0.008217200636863708,-0.008607804775238037,-0.008997395634651184,-0.00938577950000763,-0.009772971272468567],[0.010136187076568604,0.009741030633449554,0.009345486760139465,0.008949622511863708,0.008553311228752136,0.008156649768352509,0.007759653031826019,0.007362276315689087,0.006964519619941711,0.006566405296325684,0.006167970597743988,0.005769103765487671,0.005370013415813446,0.004970557987689972,0.0045708417892456055,0.004170827567577362,0.0037705600261688232,0.0033701062202453613,0.0029694288969039917,0.0025686025619506836,0.0021675825119018555,0.0017665773630142212,0.0013654455542564392,0.0009642764925956726,0.0005630329251289368,0.00016199052333831787,-0.0002389773726463318,-0.0006397739052772522,-0.001040428876876831,-0.0014408230781555176,-0.0018408894538879395,-0.0022407323122024536,-0.002640172839164734,-0.0030391663312911987,-0.003437608480453491,-0.003835618495941162,-0.004232972860336304,-0.004629641771316528,-0.0050256699323654175,-0.005420893430709839,-0.005815416574478149,-0.006209075450897217,-0.0066018253564834595,-0.006993532180786133,-0.007384300231933594,-0.00777415931224823,-0.008162811398506165,-0.008550256490707397,-0.008936628699302673,-0.009321704506874084],[0.010509759187698364,0.010116159915924072,0.009722098708152771,0.00932767242193222,0.008932895958423615,0.00853770226240158,0.008142083883285522,0.007746115326881409,0.007349781692028046,0.006953030824661255,0.006555922329425812,0.006158478558063507,0.005760706961154938,0.005362659692764282,0.004964284598827362,0.004565581679344177,0.004166699945926666,0.0037675872445106506,0.003368273377418518,0.002968825399875641,0.002569235861301422,0.002169489860534668,0.0017697587609291077,0.001370057463645935,0.0009702891111373901,0.0005706921219825745,0.00017121434211730957,-0.0002281665802001953,-0.0006273090839385986,-0.0010261237621307373,-0.0014246851205825806,-0.001822933554649353,-0.0022207647562026978,-0.0026180297136306763,-0.003014877438545227,-0.0034111738204956055,-0.0038067400455474854,-0.004201769828796387,-0.00459599494934082,-0.004989489912986755,-0.0053820013999938965,-0.005773797631263733,-0.006164610385894775,-0.0065544843673706055,-0.006943196058273315,-0.007330894470214844,-0.007717519998550415,-0.008102849125862122,-0.008487120270729065,-0.00886988639831543],[0.010881349444389343,0.010489240288734436,0.010096713900566101,0.00970379263162613,0.009310469031333923,0.008916676044464111,0.008522652089595795,0.008128024637699127,0.007733143866062164,0.007337838411331177,0.006942138075828552,0.006546154618263245,0.006149724125862122,0.005753017961978912,0.00535602867603302,0.004958800971508026,0.004561290144920349,0.004163637757301331,0.003765694797039032,0.003367580473423004,0.002969413995742798,0.0025712624192237854,0.0021728798747062683,0.0017746835947036743,0.0013764426112174988,0.0009783506393432617,0.0005802810192108154,0.000182420015335083,-0.00021508336067199707,-0.0006123483180999756,-0.0010092705488204956,-0.0014058798551559448,-0.0018020570278167725,-0.0021976083517074585,-0.002592742443084717,-0.0029872655868530273,-0.0033810436725616455,-0.0037742555141448975,-0.004166632890701294,-0.004558205604553223,-0.00494876503944397,-0.005338728427886963,-0.00572754442691803,-0.006115257740020752,-0.006502032279968262,-0.006887465715408325,-0.007272049784660339,-0.0076553672552108765,-0.008037269115447998,-0.008417919278144836],[0.011250615119934082,0.010860130190849304,0.010469160974025726,0.010077789425849915,0.009686022996902466,0.009293854236602783,0.008901223540306091,0.008508145809173584,0.008114650845527649,0.00772075355052948,0.007326558232307434,0.006931997835636139,0.006537020206451416,0.00614175945520401,0.0057462602853775024,0.005350440740585327,0.004954375326633453,0.004558101296424866,0.004161633551120758,0.0037650465965270996,0.0033683404326438904,0.002971664071083069,0.0025748834013938904,0.0021781176328659058,0.001781359314918518,0.0013848543167114258,0.0009883493185043335,0.0005921721458435059,0.0001961439847946167,-0.00019942224025726318,-0.0005947500467300415,-0.0009895861148834229,-0.001383945345878601,-0.00177784264087677,-0.0021711736917495728,-0.00256386399269104,-0.002955883741378784,-0.0033471286296844482,-0.0037375837564468384,-0.004127219319343567,-0.0045159608125686646,-0.004903703927993774,-0.005290418863296509,-0.005676165223121643,-0.006060734391212463,-0.006444185972213745,-0.006826430559158325,-0.007207438349723816,-0.007587075233459473,-0.007965415716171265],[0.01161772757768631,0.011228866875171661,0.010839462280273438,0.010449729859828949,0.010059460997581482,0.009668834507465363,0.009277716279029846,0.008886203169822693,0.008494198322296143,0.008101940155029297,0.007709182798862457,0.007316112518310547,0.006922625005245209,0.006528861820697784,0.00613480806350708,0.005740448832511902,0.0053458064794540405,0.0049510374665260315,0.004556052386760712,0.004160992801189423,0.0037658587098121643,0.003370627760887146,0.0029754340648651123,0.0025802552700042725,0.002185150980949402,0.0017901808023452759,0.0013953447341918945,0.0010007470846176147,0.0006065070629119873,0.00021250545978546143,-0.00018100440502166748,-0.0005741715431213379,-0.0009666383266448975,-0.0013587921857833862,-0.0017502456903457642,-0.0021410733461380005,-0.0025311410427093506,-0.0029204636812210083,-0.003308892250061035,-0.0036965757608413696,-0.004083290696144104,-0.004468858242034912,-0.0048536211252212524,-0.005237102508544922,-0.005619645118713379,-0.0060006678104400635,-0.006380677223205566,-0.0067593008279800415,-0.007136702537536621,-0.007512688636779785],[0.011982493102550507,0.011595331132411957,0.01120758056640625,0.01081942766904831,0.010430797934532166,0.010041743516921997,0.009652197360992432,0.00926220417022705,0.008871830999851227,0.008481010794639587,0.008089788258075714,0.007698267698287964,0.007306315004825592,0.0069140419363975525,0.006521508097648621,0.0061287060379981995,0.005735620856285095,0.005342438817024231,0.004949033260345459,0.00455552339553833,0.004161924123764038,0.0037682801485061646,0.0033746659755706787,0.002981126308441162,0.0025875866413116455,0.002194240689277649,0.0018011033535003662,0.0014082789421081543,0.001015782356262207,0.0006234943866729736,0.00023174285888671875,-0.00015944242477416992,-0.0005503743886947632,-0.0009405761957168579,-0.001329958438873291,-0.0017189085483551025,-0.002106994390487671,-0.0024943798780441284,-0.0028808414936065674,-0.003266364336013794,-0.003650873899459839,-0.004034474492073059,-0.004416942596435547,-0.004798188805580139,-0.005178362131118774,-0.005557343363761902,-0.0059349387884140015,-0.006311312317848206,-0.0066862404346466064,-0.007059633731842041],[0.01234496384859085,0.011959448456764221,0.011573418974876404,0.011186905205249786,0.01079992949962616,0.010412469506263733,0.010024584829807281,0.009636200964450836,0.009247340261936188,0.008858129382133484,0.00846850872039795,0.008078545331954956,0.007688172161579132,0.00729745626449585,0.006906561553478241,0.006515301764011383,0.0061238110065460205,0.005732178688049316,0.005340367555618286,0.004948481917381287,0.00455649197101593,0.004164576530456543,0.003772541880607605,0.0033806264400482178,0.0029889047145843506,0.002597212791442871,0.002205789089202881,0.0018147975206375122,0.0014240443706512451,0.0010335743427276611,0.0006437301635742188,0.00025425851345062256,-0.00013464689254760742,-0.0005229562520980835,-0.0009104907512664795,-0.0012974143028259277,-0.0016834735870361328,-0.0020687878131866455,-0.002453133463859558,-0.0028364360332489014,-0.0032188594341278076,-0.0036002695560455322,-0.003980457782745361,-0.004359424114227295,-0.004737406969070435,-0.005113869905471802,-0.005488991737365723,-0.005863070487976074,-0.006235465407371521,-0.0066063255071640015],[0.01270507276058197,0.012321241199970245,0.011936910450458527,0.011552147567272186,0.011166810989379883,0.010781005024909973,0.010394752025604248,0.010007977485656738,0.009620875120162964,0.009233258664608002,0.008845262229442596,0.008456900715827942,0.008068129420280457,0.007679082453250885,0.007289797067642212,0.0069001466035842896,0.0065102651715278625,0.006120301783084869,0.005730085074901581,0.005339816212654114,0.004949554800987244,0.004559189081192017,0.004169002175331116,0.0037787556648254395,0.0033887773752212524,0.0029988735914230347,0.0026093125343322754,0.002220064401626587,0.0018311291933059692,0.0014425069093704224,0.0010545551776885986,0.0006670057773590088,0.00028008222579956055,-0.0001061856746673584,-0.0004917383193969727,-0.0008765757083892822,-0.0012605637311935425,-0.001643642783164978,-0.002025917172431946,-0.0024071335792541504,-0.0027872323989868164,-0.003166303038597107,-0.0035442709922790527,-0.003921031951904297,-0.004296422004699707,-0.004670679569244385,-0.005043342709541321,-0.005414634943008423,-0.005784660577774048,-0.006153121590614319],[0.013062626123428345,0.012680597603321075,0.01229800283908844,0.011914998292922974,0.011531390249729156,0.01114734262228012,0.010762788355350494,0.010377749800682068,0.009992234408855438,0.00960627943277359,0.00921989232301712,0.008833229541778564,0.008446216583251953,0.00805874913930893,0.007671087980270386,0.007283121347427368,0.006894990801811218,0.006506666541099548,0.006118118762969971,0.0057296305894851685,0.005341053009033203,0.004952475428581238,0.00456392765045166,0.00417560338973999,0.003787308931350708,0.003399282693862915,0.003011450171470642,0.002624139189720154,0.0022371113300323486,0.0018506050109863281,0.0014643967151641846,0.0010788589715957642,0.0006939470767974854,0.0003098398447036743,-7.37309455871582e-05,-0.00045646727085113525,-0.0008382946252822876,-0.0012193024158477783,-0.0015992820262908936,-0.001978248357772827,-0.0023561418056488037,-0.00273287296295166,-0.0031084418296813965,-0.0034827440977096558,-0.003855675458908081,-0.004227340221405029,-0.004597529768943787,-0.004966378211975098,-0.005333751440048218,-0.00569954514503479],[0.013417735695838928,0.01303747296333313,0.01265675574541092,0.012275472283363342,0.01189364492893219,0.011511310935020447,0.011128529906272888,0.010745212435722351,0.01036141812801361,0.009977169334888458,0.009592533111572266,0.009207628667354584,0.00882217288017273,0.008436456322669983,0.008050493896007538,0.007664337754249573,0.007277935743331909,0.006891295313835144,0.006504535675048828,0.006117761135101318,0.005730971693992615,0.005344212055206299,0.0049574971199035645,0.004570916295051575,0.0041844844818115234,0.0037983208894729614,0.00341247022151947,0.0030270665884017944,0.002641916275024414,0.002257242798805237,0.0018732696771621704,0.001489594578742981,0.001106858253479004,0.0007247030735015869,0.0003433823585510254,-3.713369369506836e-05,-0.0004167705774307251,-0.000795513391494751,-0.0011731982231140137,-0.0015498697757720947,-0.0019254088401794434,-0.0022997409105300903,-0.0026729702949523926,-0.0030446797609329224,-0.003415137529373169,-0.0037843286991119385,-0.0041519105434417725,-0.004518270492553711,-0.004882872104644775,-0.005245953798294067],[0.013770252466201782,0.013391882181167603,0.013012990355491638,0.01263357698917389,0.01225350797176361,0.011873014271259308,0.011491984128952026,0.011110454797744751,0.010728403925895691,0.0103459432721138,0.009963057935237885,0.009579785168170929,0.00919622927904129,0.008812278509140015,0.008428029716014862,0.008043572306632996,0.007658928632736206,0.0072740912437438965,0.006889179348945618,0.006504237651824951,0.006119176745414734,0.005734339356422424,0.005349487066268921,0.004964753985404968,0.004580274224281311,0.00419597327709198,0.003812149167060852,0.003428637981414795,0.00304548442363739,0.00266304612159729,0.00228099524974823,0.0018994808197021484,0.0015187710523605347,0.0011388212442398071,0.0007596611976623535,0.0003813505172729492,3.9637088775634766e-06,-0.000372469425201416,-0.0007478296756744385,-0.0011220574378967285,-0.0014951229095458984,-0.0018670707941055298,-0.0022377073764801025,-0.0026070475578308105,-0.0029748231172561646,-0.0033415406942367554,-0.0037066787481307983,-0.0040700435638427734,-0.004432022571563721,-0.00479242205619812],[0.014120213687419891,0.013743765652179718,0.013366729021072388,0.012989118695259094,0.012610964477062225,0.012232303619384766,0.011853061616420746,0.011473320424556732,0.011093154549598694,0.010712526738643646,0.010331451892852783,0.00994989275932312,0.00956815481185913,0.009185932576656342,0.008803561329841614,0.008420944213867188,0.008038058876991272,0.007655084133148193,0.007272094488143921,0.00688895583152771,0.006505817174911499,0.0061227381229400635,0.005739837884902954,0.005357101559638977,0.004974544048309326,0.004592329263687134,0.004210442304611206,0.003828883171081543,0.0034478306770324707,0.0030674487352371216,0.0026874393224716187,0.0023083090782165527,0.0019297897815704346,0.001551985740661621,0.0011750608682632446,0.000799030065536499,0.0004238933324813843,4.988908767700195e-05,-0.0003230869770050049,-0.0006949007511138916,-0.0010654926300048828,-0.00143490731716156,-0.001803085207939148,-0.0021698176860809326,-0.0025351494550704956,-0.00289897620677948,-0.003261387348175049,-0.00362202525138855,-0.003981292247772217,-0.004338860511779785],[0.014467477798461914,0.01409294456243515,0.013717874884605408,0.01334218680858612,0.012965850532054901,0.012589141726493835,0.01221175491809845,0.011833921074867249,0.011455558240413666,0.011076793074607849,0.010697543621063232,0.01031792163848877,0.009937912225723267,0.00955769419670105,0.009177148342132568,0.008796393871307373,0.008415356278419495,0.008034303784370422,0.007653102278709412,0.007271930575370789,0.006890818476676941,0.006509646773338318,0.0061286985874176025,0.00574783980846405,0.005367353558540344,0.004987165331840515,0.004607260227203369,0.004227876663208008,0.0038489997386932373,0.0034706592559814453,0.0030928999185562134,0.0027159154415130615,0.0023396164178848267,0.0019640177488327026,0.0015894025564193726,0.001215711236000061,0.0008431524038314819,0.00047150254249572754,0.00010094046592712402,-0.0002684593200683594,-0.0006365031003952026,-0.0010033398866653442,-0.0013688653707504272,-0.0017328858375549316,-0.002095550298690796,-0.002456575632095337,-0.0028162896633148193,-0.003174319863319397,-0.00353066623210907,-0.0038853585720062256],[0.01481202244758606,0.01443944126367569,0.01406637579202652,0.013692617416381836,0.013318240642547607,0.01294340193271637,0.01256801187992096,0.012192055583000183,0.011815600097179413,0.011438675224781036,0.01106138527393341,0.010683655738830566,0.010305643081665039,0.009927257895469666,0.009548559784889221,0.009169712662696838,0.008790716528892517,0.008411556482315063,0.00803232192993164,0.00765305757522583,0.007273837924003601,0.006894797086715698,0.006515786051750183,0.006137102842330933,0.005758598446846008,0.005380541086196899,0.00500275194644928,0.004625529050827026,0.004248753190040588,0.0038726627826690674,0.003497093915939331,0.0031223446130752563,0.00274832546710968,0.0023751556873321533,0.002002909779548645,0.0016316622495651245,0.001261398196220398,0.0008922964334487915,0.0005242526531219482,0.00015750527381896973,-0.00020802021026611328,-0.0005723834037780762,-0.0009351372718811035,-0.00129660964012146,-0.0016564428806304932,-0.0020148158073425293,-0.0023716390132904053,-0.002726644277572632,-0.0030802786350250244,-0.0034318864345550537],[0.015153877437114716,0.01478327065706253,0.014412246644496918,0.014040492475032806,0.013668090105056763,0.013295188546180725,0.012921750545501709,0.012547746300697327,0.012173265218734741,0.01179833710193634,0.011422909796237946,0.011047184467315674,0.010671034455299377,0.010294616222381592,0.009917929768562317,0.009541064500808716,0.009164005517959595,0.008786842226982117,0.00840960443019867,0.00803239643573761,0.007655292749404907,0.007278174161911011,0.006901279091835022,0.006524696946144104,0.0061483681201934814,0.00577235221862793,0.005396738648414612,0.0050217509269714355,0.004647240042686462,0.00427323579788208,0.0039001554250717163,0.0035275518894195557,0.0031558573246002197,0.0027852654457092285,0.0024153441190719604,0.0020464807748794556,0.0016787350177764893,0.0013121366500854492,0.0009466558694839478,0.0005825459957122803,0.00021961331367492676,-0.0001417994499206543,-0.0005019605159759521,-0.0008606165647506714,-0.0012177526950836182,-0.0015732645988464355,-0.0019272565841674805,-0.0022794008255004883,-0.0026299208402633667,-0.002978712320327759],[0.015492729842662811,0.0151243656873703,0.0147552490234375,0.014385558664798737,0.01401527225971222,0.013644382357597351,0.013273000717163086,0.012900978326797485,0.012528479099273682,0.012155517935752869,0.01178210973739624,0.01140834391117096,0.011034220457077026,0.010659843683242798,0.010285139083862305,0.009910255670547485,0.009535253047943115,0.009160131216049194,0.008784949779510498,0.008409753441810608,0.008034676313400269,0.007659822702407837,0.007285073399543762,0.006910547614097595,0.006536364555358887,0.006162568926811218,0.005789309740066528,0.005416437983512878,0.005044221878051758,0.0046726614236831665,0.004301786422729492,0.003931775689125061,0.003562450408935547,0.003194153308868408,0.002826705574989319,0.0024604499340057373,0.002095237374305725,0.0017311125993728638,0.0013682693243026733,0.001006782054901123,0.0006467550992965698,0.00028780102729797363,-6.952881813049316e-05,-0.0004253387451171875,-0.0007795542478561401,-0.0011322498321533203,-0.0014831870794296265,-0.0018324851989746094,-0.0021799802780151367,-0.002525702118873596],[0.015828877687454224,0.015462525188922882,0.015095561742782593,0.014728032052516937,0.014359794557094574,0.013990998268127441,0.013621591031551361,0.013251617550849915,0.012881278991699219,0.012510329484939575,0.012138992547988892,0.011767253279685974,0.011395171284675598,0.011022806167602539,0.01065024733543396,0.01027737557888031,0.009904369711875916,0.009531408548355103,0.009158313274383545,0.00878530740737915,0.0084124356508255,0.008039593696594238,0.007667019963264465,0.007294744253158569,0.006922796368598938,0.00655132532119751,0.006180256605148315,0.0058097392320632935,0.0054398030042648315,0.0050706565380096436,0.004702121019363403,0.004334539175033569,0.003967761993408203,0.0036020278930664062,0.0032371431589126587,0.0028733760118484497,0.002510741353034973,0.0021492689847946167,0.0017891228199005127,0.0014303028583526611,0.001072913408279419,0.0007168948650360107,0.00036247074604034424,9.387731552124023e-06,-0.00034180283546447754,-0.000691726803779602,-0.0010396987199783325,-0.0013859570026397705,-0.001730307936668396,-0.0020729750394821167],[0.01616194099187851,0.015797853469848633,0.015433117747306824,0.015067636966705322,0.014701545238494873,0.01433485746383667,0.013967588543891907,0.01359972357749939,0.013231396675109863,0.012862592935562134,0.012493446469306946,0.012123718857765198,0.01175372302532196,0.011383533477783203,0.011012956500053406,0.010642290115356445,0.010271534323692322,0.009900584816932678,0.009529754519462585,0.009158864617347717,0.00878816843032837,0.00841762125492096,0.008047208189964294,0.007677197456359863,0.00730760395526886,0.006938338279724121,0.006569623947143555,0.00620153546333313,0.005834028124809265,0.005467146635055542,0.00510115921497345,0.0047359466552734375,0.004371821880340576,0.0040085166692733765,0.003646284341812134,0.003285139799118042,0.0029252320528030396,0.0025663822889328003,0.002209007740020752,0.0018529891967773438,0.0014983266592025757,0.0011451691389083862,0.0007935166358947754,0.00044357776641845703,9.515881538391113e-05,-0.0002514570951461792,-0.0005965381860733032,-0.0009397715330123901,-0.0012811273336410522,-0.0016204863786697388],[0.016492195427417755,0.01613030582666397,0.015767760574817657,0.015404373407363892,0.015040561556816101,0.014675937592983246,0.014310881495475769,0.013945206999778748,0.013579040765762329,0.013212397694587708,0.012845233082771301,0.0124778151512146,0.012110069394111633,0.011741891503334045,0.011373564600944519,0.011005014181137085,0.010636433959007263,0.010267719626426697,0.009899094700813293,0.009530454874038696,0.00916200876235962,0.008793681859970093,0.008425578474998474,0.008057922124862671,0.00769062340259552,0.007323816418647766,0.006957322359085083,0.006591692566871643,0.006226673722267151,0.005862310528755188,0.00549885630607605,0.005136221647262573,0.004774540662765503,0.004413828253746033,0.004054278135299683,0.0036957114934921265,0.0033386051654815674,0.0029826462268829346,0.0026279985904693604,0.002274736762046814,0.0019230246543884277,0.0015728026628494263,0.0012241452932357788,0.0008769631385803223,0.0005317032337188721,0.00018797814846038818,-0.00015385448932647705,-0.0004939734935760498,-0.0008321702480316162,-0.0011683106422424316],[0.016819320619106293,0.01645975559949875,0.01609940081834793,0.015738405287265778,0.015376672148704529,0.015014290809631348,0.014651432633399963,0.014288008213043213,0.013923987746238708,0.013559460639953613,0.013194650411605835,0.012829363346099854,0.012463688850402832,0.012097910046577454,0.011731833219528198,0.011365488171577454,0.010999172925949097,0.010632738471031189,0.0102662593126297,0.00989997386932373,0.009533897042274475,0.009167850017547607,0.00880211591720581,0.008436784148216248,0.00807178020477295,0.007707446813583374,0.0073435306549072266,0.006980195641517639,0.006617754697799683,0.006255894899368286,0.005895048379898071,0.005535021424293518,0.005175918340682983,0.004817932844161987,0.004461035132408142,0.004105299711227417,0.003750920295715332,0.0033977627754211426,0.0030459314584732056,0.0026955604553222656,0.002346813678741455,0.0019995272159576416,0.0016538053750991821,0.001309812068939209,0.0009674876928329468,0.0006268173456192017,0.00028827786445617676,-4.875659942626953e-05,-0.00038364529609680176,-0.0007165968418121338],[0.017143361270427704,0.016786091029644012,0.01642802357673645,0.01606929302215576,0.015709996223449707,0.015349894762039185,0.014989182353019714,0.014627933502197266,0.014266297221183777,0.013904094696044922,0.013541430234909058,0.013178497552871704,0.012815147638320923,0.012451499700546265,0.012087702751159668,0.011723741888999939,0.011359632015228271,0.010995447635650635,0.010631397366523743,0.010267391800880432,0.009903579950332642,0.009540006518363953,0.009176671504974365,0.008813738822937012,0.008451297879219055,0.00808928906917572,0.007727965712547302,0.007367253303527832,0.00700727105140686,0.006648078560829163,0.006289780139923096,0.005932465195655823,0.005576029419898987,0.005220741033554077,0.004866555333137512,0.004513636231422424,0.004162028431892395,0.003811851143836975,0.0034630000591278076,0.003115430474281311,0.0027696341276168823,0.0024253875017166138,0.0020827949047088623,0.0017416775226593018,0.0014025121927261353,0.0010651350021362305,0.0007295608520507812,0.00039599835872650146,6.431341171264648e-05,-0.00026544928550720215],[0.0174642875790596,0.017109379172325134,0.016753703355789185,0.016397342085838318,0.01604016125202179,0.015682518482208252,0.015324220061302185,0.014965355396270752,0.014605909585952759,0.014245957136154175,0.01388576626777649,0.013525024056434631,0.013163983821868896,0.012802690267562866,0.012441202998161316,0.012079522013664246,0.011717751622200012,0.011356070637702942,0.010994300246238708,0.010632798075675964,0.010271385312080383,0.00991019606590271,0.009549379348754883,0.009188920259475708,0.0088290274143219,0.008469536900520325,0.00811074674129486,0.007752522826194763,0.0073951780796051025,0.007038667798042297,0.006683066487312317,0.006328359246253967,0.005974680185317993,0.005622163414955139,0.005270913243293762,0.004920750856399536,0.004572078585624695,0.004224687814712524,0.0038787275552749634,0.00353434681892395,0.0031915009021759033,0.0028502941131591797,0.0025106817483901978,0.002172991633415222,0.0018369704484939575,0.0015028119087219238,0.001170426607131958,0.0008400678634643555,0.0005116313695907593,0.00018528103828430176],[0.01778210699558258,0.01742960512638092,0.017076268792152405,0.016722261905670166,0.016367599368095398,0.01601231098175049,0.015656352043151855,0.015299752354621887,0.014942780137062073,0.014585226774215698,0.01422727108001709,0.013868927955627441,0.01351022720336914,0.013151347637176514,0.012792244553565979,0.012432992458343506,0.012073680758476257,0.011714324355125427,0.011355116963386536,0.010995954275131226,0.010637015104293823,0.010278239846229553,0.009919986128807068,0.009562164545059204,0.009204640984535217,0.00884789228439331,0.008491694927215576,0.008136183023452759,0.0077814459800720215,0.00742766261100769,0.007074683904647827,0.0067229121923446655,0.006371885538101196,0.006022348999977112,0.005673721432685852,0.005326762795448303,0.004980802536010742,0.004636511206626892,0.004293546080589294,0.003952115774154663,0.003612309694290161,0.00327417254447937,0.002937883138656616,0.00260317325592041,0.0022703558206558228,0.0019395798444747925,0.0016105622053146362,0.0012835562229156494,0.0009584426879882812,0.0006354451179504395],[0.01809661090373993,0.01774655282497406,0.017395704984664917,0.017044201493263245,0.01669199764728546,0.016339033842086792,0.015985488891601562,0.015631452202796936,0.015276774764060974,0.014921694993972778,0.014566093683242798,0.014210253953933716,0.0138540118932724,0.013497486710548401,0.013140812516212463,0.012784004211425781,0.012427210807800293,0.012070447206497192,0.01171363890171051,0.011356890201568604,0.011000499129295349,0.010644420981407166,0.010288640856742859,0.009933322668075562,0.00957857072353363,0.009224370121955872,0.00887085497379303,0.008518010377883911,0.008166074752807617,0.007814973592758179,0.007464855909347534,0.00711570680141449,0.006767794489860535,0.006420999765396118,0.006075412034988403,0.0057311952114105225,0.005388304591178894,0.005047112703323364,0.004707157611846924,0.004368886351585388,0.0040321946144104,0.0036971867084503174,0.00336417555809021,0.0030327141284942627,0.0027031302452087402,0.0023756325244903564,0.002049952745437622,0.0017264783382415771,0.0014047622680664062,0.0010852068662643433],[0.018407851457595825,0.018060237169265747,0.01771196722984314,0.017362982034683228,0.017013221979141235,0.016662776470184326,0.01631172001361847,0.01596011221408844,0.015607982873916626,0.01525530219078064,0.014902263879776001,0.014548823237419128,0.014195039868354797,0.013841018080711365,0.013486981391906738,0.01313258707523346,0.012778371572494507,0.012423872947692871,0.012069717049598694,0.011715725064277649,0.011361882090568542,0.011008411645889282,0.010655179619789124,0.01030266284942627,0.009950414299964905,0.00959894061088562,0.009248137474060059,0.008898138999938965,0.008548840880393982,0.008200645446777344,0.007853448390960693,0.007507219910621643,0.00716206431388855,0.00681816041469574,0.006475672125816345,0.006134346127510071,0.0057946741580963135,0.005456358194351196,0.005119606852531433,0.0047843605279922485,0.0044510215520858765,0.004119157791137695,0.0037892013788223267,0.003461301326751709,0.003135085105895996,0.002810835838317871,0.0024885833263397217,0.002168402075767517,0.0018502473831176758,0.0015341788530349731],[0.01871567964553833,0.0183708518743515,0.018025100231170654,0.017678558826446533,0.017331361770629883,0.016983509063720703,0.016634970903396606,0.01628585159778595,0.01593630015850067,0.015586137771606445,0.015235573053359985,0.014884725213050842,0.014533504843711853,0.014182031154632568,0.013830453157424927,0.013478696346282959,0.013126954436302185,0.012775242328643799,0.012423545122146606,0.012072145938873291,0.011720985174179077,0.011370182037353516,0.011019691824913025,0.010669738054275513,0.010320380330085754,0.00997161865234375,0.009623587131500244,0.0092763751745224,0.008930057287216187,0.008584529161453247,0.008240163326263428,0.00789700448513031,0.007554829120635986,0.007213905453681946,0.006874412298202515,0.006536230444908142,0.006199449300765991,0.005864262580871582,0.005530834197998047,0.005198806524276733,0.004868566989898682,0.004540145397186279,0.004213467240333557,0.0038886964321136475,0.003565952181816101,0.003245219588279724,0.0029263198375701904,0.00260964035987854,0.002294972538948059,0.0019826889038085938],[0.01902034878730774,0.018678084015846252,0.018334880471229553,0.017990991473197937,0.017646431922912598,0.017301127314567566,0.016955167055130005,0.016608640551567078,0.016261562705039978,0.01591406762599945,0.015566065907478333,0.01521773636341095,0.014869242906570435,0.014520347118377686,0.014171391725540161,0.013822212815284729,0.01347312331199646,0.013124048709869385,0.012775152921676636,0.012426391243934631,0.012077867984771729,0.011729732155799866,0.011382073163986206,0.01103489100933075,0.010688215494155884,0.01034228503704071,0.009997069835662842,0.009652674198150635,0.009309351444244385,0.008966699242591858,0.008625388145446777,0.00828506052494049,0.007945895195007324,0.007608145475387573,0.0072717368602752686,0.006936565041542053,0.0066030919551849365,0.0062710195779800415,0.005940720438957214,0.005611911416053772,0.005285099148750305,0.00495988130569458,0.004636630415916443,0.0043152570724487305,0.003995776176452637,0.003678560256958008,0.003363311290740967,0.0030499547719955444,0.0027389824390411377,0.0024301856756210327],[0.019321471452713013,0.01898178458213806,0.018641263246536255,0.01830008625984192,0.01795811951160431,0.017615512013435364,0.0172722190618515,0.016928300261497498,0.016583934426307678,0.016239017248153687,0.015893861651420593,0.015548035502433777,0.015202179551124573,0.014856025576591492,0.014509499073028564,0.014163196086883545,0.013816818594932556,0.013470441102981567,0.013124138116836548,0.012778133153915405,0.01243242621421814,0.012087047100067139,0.011742234230041504,0.011397868394851685,0.011054113507270813,0.01071101427078247,0.01036873459815979,0.01002722978591919,0.00968661904335022,0.00934724509716034,0.009008839726448059,0.00867164134979248,0.008335575461387634,0.008000701665878296,0.007667452096939087,0.007335573434829712,0.00700514018535614,0.006676346063613892,0.006349295377731323,0.006023883819580078,0.005700260400772095,0.005378425121307373,0.005058646202087402,0.004740715026855469,0.004424721002578735,0.004111051559448242,0.0037991851568222046,0.003489583730697632,0.003182128071784973,0.002876952290534973]],\"type\":\"surface\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"t\"}},\"zaxis\":{\"title\":{\"text\":\"u(x,t)\"}},\"bgcolor\":\"white\"},\"margin\":{\"l\":65,\"r\":50,\"b\":65,\"t\":90},\"title\":{\"text\":\"Predicted Solution u(x,t)\"},\"autosize\":false,\"width\":700,\"height\":700},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('b5abe46a-f669-4824-b780-8c1ebd16c12e');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import plotly.graph_objects as go\n","from scipy.special import gamma\n","\n","# Define the neural network model\n","class PINN(tf.keras.Model):\n","    def __init__(self, activation='tanh'):\n","        super(PINN, self).__init__()\n","        self.hidden = [\n","            tf.keras.layers.Dense(64, activation=activation, kernel_initializer='he_normal'),\n","            tf.keras.layers.Dense(64, activation=activation, kernel_initializer='he_normal'),\n","            tf.keras.layers.Dense(64, activation=activation, kernel_initializer='he_normal'),\n","            tf.keras.layers.Dense(1, kernel_initializer='he_normal')\n","        ]\n","\n","    def call(self, inputs):\n","        for layer in self.hidden:\n","            inputs = layer(inputs)\n","        return inputs\n","\n","# Numerical approximation of the Caputo fractional derivative using TensorFlow operations\n","def caputo_time_derivative(u, t, alpha):\n","    dt = t[1] - t[0]\n","    u_flat = tf.reshape(u, [-1])\n","    t_flat = tf.reshape(t, [-1])\n","    u_t = tf.zeros_like(u_flat)\n","\n","    for i in range(1, len(u_flat)):\n","        t_diff = (t_flat[i] - t_flat[:i] + 1e-10)**(1 + alpha)  # Adding epsilon\n","        u_diff = (u_flat[1:i+1] - u_flat[:i])\n","        u_t = u_t + tf.concat([tf.zeros(i), tf.reduce_sum(u_diff / t_diff) * tf.ones(1), tf.zeros(len(u_flat) - i - 1)], axis=0)\n","\n","    u_t = dt**alpha / gamma(2 - alpha) * u_t\n","    return tf.reshape(u_t, [-1, 1])\n","\n","# Numerical approximation of the Riesz fractional derivative using TensorFlow operations\n","def riesz_space_derivative(u, x, beta):\n","    dx = x[1] - x[0]\n","    u_flat = tf.reshape(u, [-1])\n","    x_flat = tf.reshape(x, [-1])\n","    u_xx = tf.zeros_like(u_flat)\n","\n","    for i in range(1, len(u_flat) - 1):\n","        x_diff = (x_flat[i] - x_flat[:i] + 1e-10)**(1 + beta)  # Adding epsilon\n","        u_diff = (u_flat[i+1:i+2] - 2 * u_flat[i:i+1] + u_flat[i-1:i])\n","        u_xx = u_xx + tf.concat([tf.zeros(i), tf.reduce_sum(u_diff / x_diff) * tf.ones(1), tf.zeros(len(u_flat) - i - 1)], axis=0)\n","\n","    u_xx = dx**beta / gamma(2 - beta) * u_xx\n","    return tf.reshape(u_xx, [-1, 1])\n","\n","# Loss function\n","def loss_function(model, x, t, alpha, beta, v, D):\n","    with tf.GradientTape(persistent=True) as tape:\n","        tape.watch(x)\n","        tape.watch(t)\n","        inputs = tf.concat([x, t], axis=1)\n","        u = model(inputs)\n","        u_x = tape.gradient(u, x)\n","    u_t = caputo_time_derivative(u, t, alpha)\n","    u_xx = riesz_space_derivative(u, x, beta)\n","    pde_loss = u_t + v * u_x - D * u_xx\n","\n","    print(\"Intermediate values:\")\n","    print(\"u:\", u.numpy())\n","    print(\"u_x:\", u_x.numpy())\n","    print(\"u_t:\", u_t.numpy())\n","    print(\"u_xx:\", u_xx.numpy())\n","    print(\"pde_loss:\", pde_loss.numpy())\n","\n","    return tf.reduce_mean(pde_loss**2)\n","\n","# Training\n","model = PINN()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)  # Reduced learning rate\n","\n","# Define training data\n","x = np.linspace(0, 1, 10).reshape(-1, 1).astype(np.float32)\n","t = np.linspace(0, 1, 10).reshape(-1, 1).astype(np.float32)\n","X, T = np.meshgrid(x, t)\n","X_flat = X.flatten().reshape(-1, 1)\n","T_flat = T.flatten().reshape(-1, 1)\n","\n","X_flat_tensor = tf.convert_to_tensor(X_flat, dtype=tf.float32)\n","T_flat_tensor = tf.convert_to_tensor(T_flat, dtype=tf.float32)\n","\n","# Generate initial condition u(x,0) = sin(pi * x)\n","initial_condition = np.sin(np.pi * x).astype(np.float32)\n","\n","# Training loop\n","alpha = 0.8  # example value\n","beta = 1.2  # example value\n","v = 1.0  # example value\n","D = 1.0  # example value\n","\n","epochs = 100\n","for epoch in range(epochs):\n","    with tf.GradientTape() as tape:\n","        loss = loss_function(model, X_flat_tensor, T_flat_tensor, alpha, beta, v, D)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    gradients = [tf.clip_by_value(g, -1.0, 1.0) for g in gradients]  # Apply gradient clipping\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    if epoch % 100 == 0:\n","        print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n","\n","# Predicting u_pred\n","predictions = model(tf.concat([X_flat_tensor, T_flat_tensor], axis=1))\n","u_pred = predictions.numpy().reshape(X.shape)  # Reshape to match X (10x10 grid)\n","\n","# Plotting the result using Plotly\n","fig = go.Figure(data=[\n","    go.Surface(z=u_pred, x=X, y=T, colorscale='Viridis')\n","])\n","\n","fig.update_layout(\n","    title='Predicted Solution u(x,t)',\n","    scene=dict(\n","        xaxis_title='x',\n","        yaxis_title='t',\n","        zaxis_title='u(x,t)',\n","        bgcolor='white'\n","    ),\n","    autosize=False,\n","    width=700,\n","    height=700,\n","    margin=dict(l=65, r=50, b=65, t=90)\n",")\n","\n","fig.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"zmyn0UUwA7es","executionInfo":{"status":"ok","timestamp":1718510966597,"user_tz":-330,"elapsed":128617,"user":{"displayName":"Rajarshi Dey","userId":"16792560365877080833"}},"outputId":"f55447cf-5d39-4e7e-c580-210eabd68f31"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_x: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_t: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_xx: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [ 0.]]\n","pde_loss: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","Intermediate values:\n","u: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_x: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_t: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_xx: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [ 0.]]\n","pde_loss: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","Intermediate values:\n","u: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_x: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_t: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_xx: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [ 0.]]\n","pde_loss: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","Intermediate values:\n","u: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_x: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_t: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_xx: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [ 0.]]\n","pde_loss: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","Intermediate values:\n","u: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_x: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_t: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_xx: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [ 0.]]\n","pde_loss: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","Intermediate values:\n","u: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_x: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_t: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_xx: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [ 0.]]\n","pde_loss: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","Intermediate values:\n","u: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_x: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_t: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_xx: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [ 0.]]\n","pde_loss: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","Intermediate values:\n","u: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_x: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_t: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_xx: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [ 0.]]\n","pde_loss: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","Intermediate values:\n","u: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_x: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_t: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_xx: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [ 0.]]\n","pde_loss: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","Intermediate values:\n","u: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_x: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_t: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","u_xx: [[ 0.]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [ 0.]]\n","pde_loss: [[nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"4563b2a7-1db8-428d-b36e-d2863eda5755\" class=\"plotly-graph-div\" style=\"height:700px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4563b2a7-1db8-428d-b36e-d2863eda5755\")) {                    Plotly.newPlot(                        \"4563b2a7-1db8-428d-b36e-d2863eda5755\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0],[0.0,0.1111111119389534,0.2222222238779068,0.3333333432674408,0.4444444477558136,0.5555555820465088,0.6666666865348816,0.7777777910232544,0.8888888955116272,1.0]],\"y\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1111111119389534,0.1111111119389534,0.1111111119389534,0.1111111119389534,0.1111111119389534,0.1111111119389534,0.1111111119389534,0.1111111119389534,0.1111111119389534,0.1111111119389534],[0.2222222238779068,0.2222222238779068,0.2222222238779068,0.2222222238779068,0.2222222238779068,0.2222222238779068,0.2222222238779068,0.2222222238779068,0.2222222238779068,0.2222222238779068],[0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408],[0.4444444477558136,0.4444444477558136,0.4444444477558136,0.4444444477558136,0.4444444477558136,0.4444444477558136,0.4444444477558136,0.4444444477558136,0.4444444477558136,0.4444444477558136],[0.5555555820465088,0.5555555820465088,0.5555555820465088,0.5555555820465088,0.5555555820465088,0.5555555820465088,0.5555555820465088,0.5555555820465088,0.5555555820465088,0.5555555820465088],[0.6666666865348816,0.6666666865348816,0.6666666865348816,0.6666666865348816,0.6666666865348816,0.6666666865348816,0.6666666865348816,0.6666666865348816,0.6666666865348816,0.6666666865348816],[0.7777777910232544,0.7777777910232544,0.7777777910232544,0.7777777910232544,0.7777777910232544,0.7777777910232544,0.7777777910232544,0.7777777910232544,0.7777777910232544,0.7777777910232544],[0.8888888955116272,0.8888888955116272,0.8888888955116272,0.8888888955116272,0.8888888955116272,0.8888888955116272,0.8888888955116272,0.8888888955116272,0.8888888955116272,0.8888888955116272],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]],\"z\":[[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null]],\"type\":\"surface\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"t\"}},\"zaxis\":{\"title\":{\"text\":\"u(x,t)\"}},\"bgcolor\":\"white\"},\"margin\":{\"l\":65,\"r\":50,\"b\":65,\"t\":90},\"title\":{\"text\":\"Predicted Solution u(x,t)\"},\"autosize\":false,\"width\":700,\"height\":700},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('4563b2a7-1db8-428d-b36e-d2863eda5755');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from scipy import special\n","\n","# Disable TensorFlow eager execution for performance\n","tf.compat.v1.disable_eager_execution()\n"],"metadata":{"id":"d-1y5BHdTZSA","executionInfo":{"status":"ok","timestamp":1718513589466,"user_tz":-330,"elapsed":456,"user":{"displayName":"Rajarshi Dey","userId":"16792560365877080833"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["class PINN(tf.keras.Model):\n","    def __init__(self):\n","        super(PINN, self).__init__()\n","        self.dense1 = keras.layers.Dense(50, activation='tanh', input_dim=2)  # Input layer\n","        self.dense2 = keras.layers.Dense(50, activation='tanh')\n","        self.dense3 = keras.layers.Dense(1, activation=None)  # Output layer\n","\n","    def call(self, inputs):\n","        x = self.dense1(inputs)\n","        x = self.dense2(x)\n","        u = self.dense3(x)\n","        return u\n"],"metadata":{"id":"Y1Tq4Kh1ZFhS","executionInfo":{"status":"ok","timestamp":1718513597892,"user_tz":-330,"elapsed":631,"user":{"displayName":"Rajarshi Dey","userId":"16792560365877080833"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def fractional_derivative(u, x, alpha):\n","    # Function to compute fractional derivative of u with respect to x of order alpha\n","    dx = x[1] - x[0]\n","    N = len(x)\n","    D = np.zeros((N, N))\n","\n","    for i in range(N):\n","        for j in range(N):\n","            if i != j:\n","                D[i, j] = (x[i] - x[j])**(-alpha) * special.gamma(alpha + 1) / (special.gamma(1 - alpha) * dx**alpha)\n","            else:\n","                D[i, j] = -np.pi / (2 * dx**(1 + alpha)) * special.gamma(-alpha - 1)\n","\n","    return np.dot(D, u)\n","\n","\n","def physics_loss(model, x_phys, t_phys, x_col, t_col, alpha, beta, v, D):\n","    # Function to compute the physics-informed loss\n","\n","    def advection_diffusion_eq(x, t):\n","        # Define the advection-diffusion equation\n","        with tf.GradientTape(persistent=True) as tape:\n","            tape.watch(x)\n","            tape.watch(t)\n","            u = model(tf.stack([x, t], axis=1))\n","            du_dx = tape.gradient(u, x)\n","            du_dt = tape.gradient(u, t)\n","\n","        # Compute fractional derivatives\n","        du_dx_alpha = fractional_derivative(du_dx.numpy(), x.numpy(), alpha)\n","        du_dt_alpha = fractional_derivative(du_dt.numpy(), t.numpy(), alpha)\n","\n","        # Advection-diffusion equation residual\n","        residual = du_dt_alpha + v * du_dx_alpha - D * tf.gradients(tf.gradients(u, x), x)\n","\n","        return residual\n","\n","    loss = tf.reduce_mean(tf.square(advection_diffusion_eq(x_col, t_col)))\n","\n","    return loss\n"],"metadata":{"id":"3YrqEbkcZHhw","executionInfo":{"status":"ok","timestamp":1718513615617,"user_tz":-330,"elapsed":470,"user":{"displayName":"Rajarshi Dey","userId":"16792560365877080833"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def fractional_derivative(u, x, alpha):\n","    # Function to compute fractional derivative of u with respect to x of order alpha\n","    dx = x[1] - x[0]\n","    N = len(x)\n","    D = np.zeros((N, N))\n","\n","    for i in range(N):\n","        for j in range(N):\n","            if i != j:\n","                D[i, j] = (x[i] - x[j])**(-alpha) * special.gamma(alpha + 1) / (special.gamma(1 - alpha) * dx**alpha)\n","            else:\n","                D[i, j] = -np.pi / (2 * dx**(1 + alpha)) * special.gamma(-alpha - 1)\n","\n","    return np.dot(D, u)\n","\n","\n","def physics_loss(model, x_phys, t_phys, x_col, t_col, alpha, beta, v, D):\n","    # Function to compute the physics-informed loss\n","\n","    def advection_diffusion_eq(x, t):\n","        # Define the advection-diffusion equation\n","        with tf.GradientTape(persistent=True) as tape:\n","            tape.watch(x)\n","            tape.watch(t)\n","            u = model(tf.stack([x, t], axis=1))\n","            du_dx = tape.gradient(u, x)\n","            du_dt = tape.gradient(u, t)\n","\n","        # Compute fractional derivatives\n","        du_dx_alpha = fractional_derivative(du_dx.numpy(), x.numpy(), alpha)\n","        du_dt_alpha = fractional_derivative(du_dt.numpy(), t.numpy(), alpha)\n","\n","        # Advection-diffusion equation residual\n","        residual = du_dt_alpha + v * du_dx_alpha - D * tf.gradients(tf.gradients(u, x), x)\n","\n","        return residual\n","\n","    loss = tf.reduce_mean(tf.square(advection_diffusion_eq(x_col, t_col)))\n","\n","    return loss\n"],"metadata":{"id":"OWrPvWpQZL5q","executionInfo":{"status":"ok","timestamp":1718513627727,"user_tz":-330,"elapsed":450,"user":{"displayName":"Rajarshi Dey","userId":"16792560365877080833"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def boundary_conditions(model, x_initial, u_initial, x_boundary, u_boundary):\n","    # Function to enforce initial and boundary conditions\n","    loss_init = tf.reduce_mean(tf.square(model(x_initial) - u_initial))\n","    loss_boundary = tf.reduce_mean(tf.square(model(x_boundary) - u_boundary))\n","\n","    return loss_init + loss_boundary\n"],"metadata":{"id":"i5EpyAhbZO3T","executionInfo":{"status":"ok","timestamp":1718513646133,"user_tz":-330,"elapsed":469,"user":{"displayName":"Rajarshi Dey","userId":"16792560365877080833"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def train_PINN(model, x_initial, u_initial, x_boundary, u_boundary, x_phys, t_phys, x_col, t_col, alpha, beta, v, D, epochs):\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","\n","    for epoch in range(epochs):\n","        with tf.GradientTape() as tape:\n","            loss_phys = physics_loss(model, x_phys, t_phys, x_col, t_col, alpha, beta, v, D)\n","            loss_bc = boundary_conditions(model, x_initial, u_initial, x_boundary, u_boundary)\n","            total_loss = loss_phys + loss_bc\n","\n","        grads = tape.gradient(total_loss, model.trainable_variables)\n","        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","        if epoch % 100 == 0:\n","            print(f'Epoch {epoch+1}, Total Loss: {total_loss.numpy()}, Physics Loss: {loss_phys.numpy()}, BC Loss: {loss_bc.numpy()}')\n","\n","    print('Training completed.')\n"],"metadata":{"id":"07WuGRuBZgAP","executionInfo":{"status":"ok","timestamp":1718513708019,"user_tz":-330,"elapsed":447,"user":{"displayName":"Rajarshi Dey","userId":"16792560365877080833"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Example usage\n","# Define your initial and boundary conditions, physical parameters, etc.\n","\n","# Initialize PINN model\n","model = PINN()\n","\n","# Define your training data (initial conditions, boundary conditions, collocation points, etc.)\n","\n","# Train the PINN\n","train_PINN(model, x_initial, u_initial, x_boundary, u_boundary, x_phys, t_phys, x_col, t_col, alpha, beta, v, D, epochs=1000)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"id":"ktScIt7RZVFB","executionInfo":{"status":"error","timestamp":1718513678866,"user_tz":-330,"elapsed":477,"user":{"displayName":"Rajarshi Dey","userId":"16792560365877080833"}},"outputId":"8d00da07-e3ef-4253-d0b5-d0dd195cf87f"},"execution_count":21,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'x_initial' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-906936eac356>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Train the PINN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_PINN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_boundary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_boundary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_phys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_phys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'x_initial' is not defined"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf # Import tensorflow at the beginning\n","from tensorflow import keras\n","from scipy import special\n","import plotly.graph_objs as go\n","import plotly.io as pio\n","\n","# Enable eager execution\n","# tf.compat.v1.enable_eager_execution()\n","\n","# Define the PINN model class\n","class PINN(tf.keras.Model):\n","    def __init__(self):\n","        super(PINN, self).__init__()\n","        self.dense1 = keras.layers.Dense(50, activation='tanh', input_dim=2)  # Input layer\n","        self.dense2 = keras.layers.Dense(50, activation='tanh')\n","        self.dense3 = keras.layers.Dense(1, activation=None)  # Output layer\n","\n","    def call(self, inputs):\n","        x = self.dense1(inputs)\n","        x = self.dense2(x)\n","        u = self.dense3(x)\n","        return u\n","\n","def fractional_derivative(u, x, alpha):\n","    dx = x[1] - x[0]\n","    N = x.shape[0]\n","    D = np.zeros((N, N))\n","\n","    for i in range(N):\n","        for j in range(N):\n","            if i != j:\n","                D[i, j] = (x[i] - x[j])**(-alpha) * special.gamma(alpha + 1) / (special.gamma(1 - alpha) * dx**alpha)\n","            else:\n","                # Convert dx to a NumPy array before using it in calculations\n","                D[i, j] = -np.pi / (2 * dx.numpy()**(1 + alpha)) * special.gamma(-alpha - 1)\n","\n","    return np.dot(D, u)\n","\n","def physics_loss(model, x_phys, t_phys, x_col, t_col, alpha, beta, v, D):\n","    def advection_diffusion_eq(x, t):\n","        with tf.GradientTape(persistent=True) as tape:\n","            tape.watch(x)\n","            tape.watch(t)\n","            u = model(tf.stack([x, t], axis=1))\n","            du_dx = tape.gradient(u, x)\n","            du_dt = tape.gradient(u, t)\n","\n","        # Convert TensorFlow tensors to NumPy arrays before passing them to fractional_derivative\n","        du_dx_alpha = fractional_derivative(du_dx.numpy(), x.numpy(), alpha)\n","        du_dt_alpha = fractional_derivative(du_dt.numpy(), t.numpy(), alpha)\n","\n","        residual = du_dt_alpha + v * du_dx_alpha - D * tf.gradients(tf.gradients(u, x), x)\n","\n","        return residual\n","\n","    loss = tf.reduce_mean(tf.square(advection_diffusion_eq(x_col, t_col)))\n","\n","    return loss\n","\n","def boundary_conditions(model, x_initial, u_initial, x_boundary, u_boundary):\n","    x_boundary_tf = tf.constant(x_boundary, dtype=tf.float32)\n","    u_boundary_tf = tf.constant(u_boundary, dtype=tf.float32)\n","\n","    loss_init = tf.reduce_mean(tf.square(model(x_initial) - u_initial))\n","    loss_boundary = tf.reduce_mean(tf.square(model(x_boundary_tf) - u_boundary_tf))\n","\n","    return loss_init + loss_boundary\n","\n","def train_PINN(model, x_initial, u_initial, x_boundary, u_boundary, x_phys, t_phys, x_col, t_col, alpha, beta, v, D, epochs):\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","\n","    # Convert numpy arrays to TensorFlow tensors\n","    x_initial_tf = tf.constant(x_initial, dtype=tf.float32)\n","    u_initial_tf = tf.constant(u_initial, dtype=tf.float32)\n","    x_boundary_tf = tf.constant(x_boundary, dtype=tf.float32)\n","    u_boundary_tf = tf.constant(u_boundary, dtype=tf.float32)\n","    x_phys_tf = tf.constant(x_phys, dtype=tf.float32)\n","    t_phys_tf = tf.constant(t_phys, dtype=tf.float32)\n","    x_col_tf = tf.constant(x_col, dtype=tf.float32)\n","    t_col_tf = tf.constant(t_col, dtype=tf.float32)\n","\n","    for epoch in range(epochs):\n","        with tf.GradientTape() as tape:\n","            loss_phys = physics_loss(model, x_phys_tf, t_phys_tf, x_col_tf, t_col_tf, alpha, beta, v, D)\n","            loss_bc = boundary_conditions(model, x_initial_tf, u_initial_tf, x_boundary_tf, u_boundary_tf)\n","            total_loss = loss_phys + loss_bc\n","\n","        grads = tape.gradient(total_loss, model.trainable_variables)\n","        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","        if epoch % 100 == 0:\n","            print(f'Epoch {epoch+1}, Total Loss: {total_loss.numpy()}, Physics Loss: {loss_phys.numpy()}, BC Loss: {loss_bc.numpy()}')\n","\n","    print('Training completed.')\n","\n","def plot_solution(model, x, t, title):\n","    X, T = np.meshgrid(x, t)\n","    X_flat = X.flatten()[:, None]\n","    T_flat = T.flatten()[:, None]\n","    inputs = np.hstack((X_flat, T_flat))\n","\n","    U_pred = model.predict(inputs)\n","    U_pred = np.reshape(U_pred, X.shape)\n","\n","    fig = go.Figure(data=[go.Surface(x=X, y=T, z=U_pred)])\n","    fig.update_layout(title=title, autosize=False,\n","                      scene=dict(\n","                          xaxis=dict(title='x'),\n","                          yaxis=dict(title='t'),\n","                          zaxis=dict(title='u(x,t)'),\n","                      ))\n","    pio.show(fig)\n","\n","# Example usage\n","\n","# Define the domain and parameters\n","x_initial = np.linspace(0, 1, 100)[:, None]  # Initial condition points\n","u_initial = np.sin(np.pi * x_initial)       # Initial condition values\n","\n","x_boundary = np.array([[0.0], [1.0]])        # Boundary points (example endpoints)\n","u_boundary = np.zeros_like(x_boundary)      # Boundary condition values (example: zero at boundaries)\n","\n","x_phys = np.random.uniform(0, 1, (1000, 1))  # Collocation points in the domain\n","t_phys = np.random.uniform(0, 1, (1000, 1))  # Time points for collocation\n","\n","x_col = np.random.uniform(0, 1, (1000, 1))   # Collocation points in x-direction\n","t_col = np.random.uniform(0, 1, (1000, 1))   # Collocation points in t-direction\n","\n","alpha = 0.5  # Fractional derivative order in time and space\n","beta = 1.0   # Fractional derivative order in space\n","v = 1.0      # Advection velocity\n","D = 0.1      # Diffusion coefficient\n","\n","# Initialize PINN model\n","model = PINN()\n","\n","# Train the PINN\n","train_PINN(model, x_initial, u_initial, x_boundary, u_boundary, x_phys, t_phys, x_col, t_col, alpha, beta, v, D, epochs=1000)\n","\n","# Plot the solution using Plotly\n","x_plot = np.linspace(0, 1, 100)\n","t_plot = np.linspace(0, 1, 100)\n","plot_solution(model, x_plot, t_plot, title='Solution of Fractional Advection-Diffusion Equation')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"id":"g8-BdMhTZbVe","executionInfo":{"status":"error","timestamp":1718514402964,"user_tz":-330,"elapsed":1186,"user":{"displayName":"Rajarshi Dey","userId":"16792560365877080833"}},"outputId":"e7268e6e-9cb0-4f45-edcb-eca6c35778e7"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n","WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'SymbolicTensor' object has no attribute 'numpy'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-422721064237>\u001b[0m in \u001b[0;36m<cell line: 139>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;31m# Train the PINN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m \u001b[0mtrain_PINN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_boundary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_boundary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_phys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_phys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;31m# Plot the solution using Plotly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-33-422721064237>\u001b[0m in \u001b[0;36mtrain_PINN\u001b[0;34m(model, x_initial, u_initial, x_boundary, u_boundary, x_phys, t_phys, x_col, t_col, alpha, beta, v, D, epochs)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mloss_phys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphysics_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_phys_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_phys_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_col_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_col_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mloss_bc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboundary_conditions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_initial_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_initial_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_boundary_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_boundary_tf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_phys\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_bc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-33-422721064237>\u001b[0m in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_phys, t_phys, x_col, t_col, alpha, beta, v, D)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madvection_diffusion_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-33-422721064237>\u001b[0m in \u001b[0;36madvection_diffusion_eq\u001b[0;34m(x, t)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# Convert TensorFlow tensors to NumPy arrays before passing them to fractional_derivative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mdu_dx_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfractional_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdu_dx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mdu_dt_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfractional_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdu_dt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_enable_numpy_behavior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \"\"\")\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'SymbolicTensor' object has no attribute 'numpy'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"guKgbQHdZyNr"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOs53DwmfZYtikuQRjsy9PU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}